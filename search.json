[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ateliers L3 CMI",
    "section": "",
    "text": "Introduction",
    "crumbs": [
      "Général",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#présentation",
    "href": "index.html#présentation",
    "title": "Ateliers L3 CMI",
    "section": "Présentation",
    "text": "Présentation\nCe livre contient les supports de TP des quatre ateliers spécifiques de la L3 CMI de l’université Paris Nanterre :\n\nCalcul numérique (S1) – 3 ECTS\nSystème d’information géographique (S1) – 3 ECTS\nEconométrie 1 (S1) – 4.5 ECTS\nEconométrie 2 (S2) – 3 ECTS",
    "crumbs": [
      "Général",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#notation",
    "href": "index.html#notation",
    "title": "Ateliers L3 CMI",
    "section": "Notation",
    "text": "Notation\nToute la notation est en contrôle continu. Les notes viennent de :\n\n« Participation » qui inclut l’implication en classe, la qualité des rendus des TP et des pénalités pour retards et absences non justifiées\nPrésentations en classe\nProjets de fin de semestre :\n\nPeuvent être communs à plusieurs matières\nSujets donnés ou sujets libres\n\nRapport écrit propre (pas de compilation de code, ou de génération IA)\nPrésentation orale avec slides (sans les lire)\n\n\nToutes les projets sont recensés dans ce fichier Excel partagé.\nMe contacter à qhoarau@parisnanterre.fr.",
    "crumbs": [
      "Général",
      "Introduction"
    ]
  },
  {
    "objectID": "CMI-projets.html",
    "href": "CMI-projets.html",
    "title": "Projets et présentations",
    "section": "",
    "text": "Lien d’inscription\nToutes les projets sont recensés dans ce fichier Excel partagé.",
    "crumbs": [
      "Général",
      "Projets et présentations"
    ]
  },
  {
    "objectID": "CMI-projets.html#résumé-des-consignes",
    "href": "CMI-projets.html#résumé-des-consignes",
    "title": "Projets et présentations",
    "section": "Résumé des consignes",
    "text": "Résumé des consignes\n\nProjet 1\nProjet en deux parties :\n\nPartie 1 (30% du projet) : travail SIG. Réalisation et discussion d’une carte avec QGIS. Export de la carte en pdf/jpeg/… pas de capture d’écran.\nPartie 2 (70% du projet) : travail Calcul Numérique - Econométrie : réalisation d’un travail sur des données trouvées par l’étudiant.\n\nRendus : slides + script R. A déposer sur CEL.\nPrésentation : 15 minutes + 5 minutes de question\nDate de présentation : mercredi 3 décembre à partir de 14h\n\n\nProjet 2\nProjet en deux parties :\n\nPartie 1 (40% du projet) : travail SIG\nPartie 2 (60% du projet) : travail Econométrie : réalisation d’un travail sur les données sur des données imposées.\n\nRendus : slides + rapport + (10 pages de texte à remettre la veille) + script R. Pas de capture d’écran. A deposer sur CEL.\nPrésentation : 15 minutes + 5 minutes de question\nDate de présentation : mardi 16 décembre à partir de 8h30\n\n\nProjet 3\nCe projet reprend le projet 2 mais avec une perspective d’inférence causale. Il s’agira d’utiliser une méthode de différences en différences échelonnées (DiD), voir une event study. Le traitement sera défini par le croisement la proximité à une installation (éolienne, usine) ou élément naturel (foret, cours d’eau) après l’apparititon. Par exemple, la proximité à une éolienne après sons ouverture, la proximité à un cours d’eau après une inondation, la proximité à une forêt après un incendie.",
    "crumbs": [
      "Général",
      "Projets et présentations"
    ]
  },
  {
    "objectID": "CMI-Projet1.html",
    "href": "CMI-Projet1.html",
    "title": "Consignes Projet 1",
    "section": "",
    "text": "Consignes Générales",
    "crumbs": [
      "Général",
      "Consignes Projet 1"
    ]
  },
  {
    "objectID": "CMI-Projet1.html#partie-sig",
    "href": "CMI-Projet1.html#partie-sig",
    "title": "Consignes Projet 1",
    "section": "Partie SIG",
    "text": "Partie SIG\nRéalisation d’une carte à partir de données originales trouvées par l’étudiant. La carte doit répondre à une problématique\nExemples : - carte représentant la position de certains restaurants sur une carte chloropèthe sur les revenus",
    "crumbs": [
      "Général",
      "Consignes Projet 1"
    ]
  },
  {
    "objectID": "CMI-Projet1.html#partie-calcul-numérique-et-econométrie",
    "href": "CMI-Projet1.html#partie-calcul-numérique-et-econométrie",
    "title": "Consignes Projet 1",
    "section": "Partie Calcul Numérique et Econométrie",
    "text": "Partie Calcul Numérique et Econométrie\nRéalisation d’analyse de données originales trouvées par l’étudiant. Pas nécessairement les mêmes que pour la partie SIG.",
    "crumbs": [
      "Général",
      "Consignes Projet 1"
    ]
  },
  {
    "objectID": "CMI-Projet1.html#évaluation",
    "href": "CMI-Projet1.html#évaluation",
    "title": "Consignes Projet 1",
    "section": "Évaluation",
    "text": "Évaluation\n\nRendus :  slides + carte (en pdf/jpg mais pas de capture d’écran)\nPrésentation :  15 minutes + 5 minutes de question\nDate de présentation : mercredi 3 décembre à partir de 14h",
    "crumbs": [
      "Général",
      "Consignes Projet 1"
    ]
  },
  {
    "objectID": "CMI-Projet2.html",
    "href": "CMI-Projet2.html",
    "title": "Consignes Projet 2",
    "section": "",
    "text": "Consignes Générales\nDans ce projet, vous devez combiner deux jeux de données pour faire une analyse économétrique et SIG. Tous les sujets s’intéressent aux effets de capitalisation dans l’immobilier : comment le marché immobilier valorise-t-il tel ou tel aspect de l’environnement proche du bien ?\nPar exemple : - l’installation d’éoliennes, de méthaniseurs, ou de centrale solaire provoquent-elles des nuisances qui entrainent une baisse des prix des maisons ? - Les inondations font-elles perdre de la valeur aux maisons proches des cours d’eau ?\nTout l’enjeu de ces sujets est de quantifier précisément ces effets à l’aide de modèles économétriques du type :\n\\[log(valeur bien) = 1(distance &lt; X km) + controles \\]\navec \\(1(distance &lt; X km)\\) un dummy valant 1 si le bien est à moins de X km de la nuisance.",
    "crumbs": [
      "Général",
      "Consignes Projet 2"
    ]
  },
  {
    "objectID": "CMI-Projet2.html#consignes-générales",
    "href": "CMI-Projet2.html#consignes-générales",
    "title": "Consignes Projet 2",
    "section": "",
    "text": "Les sujets sont volontairement simples et vagues : il vous appartient de vous les approprier.\n\nApporter du contexte avec vos recherches personnelles.\n\nDécrire les métadonnées : origine, limites, etc.\n\nDécrire les données : taille, horizon géographique et temporel, grandeurs et catégories contenues. Colonnes utiles vs inutiles. Nombre de données manquantes.\n\nVous pouvez rapprocher les données que vous avez.\n\nSi les données sont trop lourdes, il est accepté de restreindre le jeu de données à une aire temporelle plus réduite.",
    "crumbs": [
      "Général",
      "Consignes Projet 2"
    ]
  },
  {
    "objectID": "CMI-Projet2.html#partie-sig",
    "href": "CMI-Projet2.html#partie-sig",
    "title": "Consignes Projet 2",
    "section": "Partie SIG",
    "text": "Partie SIG\n\nRéaliser des cartes générales (choroplèthes) à l’échelle de la France pour chaque jeu de données.\n\nRéaliser des cartes combinées lorsqu’un même sujet fait apparaître deux jeux de données.\n\nExemple : une carte « zoom » avec des icônes différentes pour localiser les éoliennes et les maisons vendues à proximité.\n\n\nCalculer les distances pour rapprocher les deux bases :\n\nPour chaque bien immobilier, quelle est l’éolienne la plus proche ?\n\n\nCalculer les distances en intégrant la dimension temporelle.\n\nRestreindre le jeu de données aux observations pertinentes (ex. moins de 10 km autour de chaque évènement).\n\nExemple : enlever les maisons vendues à plus de 15 km d’une éolienne qui sera installée en 2024.",
    "crumbs": [
      "Général",
      "Consignes Projet 2"
    ]
  },
  {
    "objectID": "CMI-Projet2.html#partie-économétrie",
    "href": "CMI-Projet2.html#partie-économétrie",
    "title": "Consignes Projet 2",
    "section": "Partie Économétrie",
    "text": "Partie Économétrie\n\nFaire des statistiques descriptives sur chaque jeu de données :\n\nExemple : évolution du nombre d’éoliennes installées/fermées, caractéristiques moyennes des évènements.\n\n\nFaire des statistiques descriptives sur la réunion des deux jeux de données :\n\nExemple : évolution du prix en fonction de la distance aux éoliennes.\n\n\nEstimer plusieurs régressions sur les prix de l’immobilier sans le deuxième jeu de données :\n\nExemple :\n\\(\\log(Prix) = nb\\_pieces + surface + departement + année + \\dots\\)\n\nEstimer plusieurs régressions sur les prix de l’immobilier avec le deuxième jeu de données :\n\nExemple :\n\\(\\log(Prix) = (distance &lt; 1km) + nb\\_pieces + surface + dep + année + \\dots\\)",
    "crumbs": [
      "Général",
      "Consignes Projet 2"
    ]
  },
  {
    "objectID": "CMI-Projet2.html#rapport",
    "href": "CMI-Projet2.html#rapport",
    "title": "Consignes Projet 2",
    "section": "Rapport",
    "text": "Rapport\n\nConstruire une problématique :\n\nExemple : Quel est l’impact de l’installation d’éoliennes sur les prix des maisons en zone rurale ?\n\n\nExpliciter le mécanisme à l’œuvre :\n\nExemple : Une fermeture d’usine entraîne moins de travailleurs (donc baisse de la demande), mais aussi moins de pollution (hausse de la demande).\n\n\nPlan imposé :\n\nIntroduction + problématique + contexte + présentation des données\n\nSIG\n\nÉconométrie\n\n\nRédaction :\n\nPas moins de 10 pages.\n\nÉcrit en Word ou LaTeX (pas de knit en Markdown).\n\n\nPrésentation :\n\nPowerPoint de 15 minutes + 5 minutes de questions.",
    "crumbs": [
      "Général",
      "Consignes Projet 2"
    ]
  },
  {
    "objectID": "CMI-Projet2.html#évaluation",
    "href": "CMI-Projet2.html#évaluation",
    "title": "Consignes Projet 2",
    "section": "Évaluation",
    "text": "Évaluation\n\nRendus : slides et rapport sur CEL\nPrésentation : 15 minutes + 5 minutes de question\nDate de rendu du projet : 15 décembre à 16h\nDate de présentation : 16 décembre à partir de 8h30",
    "crumbs": [
      "Général",
      "Consignes Projet 2"
    ]
  },
  {
    "objectID": "CMI-Projet2.html#données",
    "href": "CMI-Projet2.html#données",
    "title": "Consignes Projet 2",
    "section": "Données",
    "text": "Données\n\nLiens :\n\nImmobilier\nEolien\nSolaire\nMethaniseurs\nStations de recharge\nParc véhicules électriques\nIncendies\nCours d’eau\nInondations\nFiscalité locale\nDonnées Socioéconomiques\nCLC\nBPE\nInstallations polluantes\n\n\n\nImmobiliers\nLien :\n\n\nEolien\nAttention aux coordonnées gps des éoliennes (il faut diviser les x /10 ou 100 selon)\n\n\nMéthaniseurs\n\n\nInondations\nL’idéal est de rajouter les distances aux cours d’eau pour capturer la vulnérabilité aux inondations.\n\n\nIncendies\nLa base de données proposer porte sur les incendies de forets, en particulier dans l’aire Méditerranéenne. L’idéal est de rajouter les distances aux forêts pour capturer la vulnérabilité aux incendies de forêts.\n\n\nInstallations polluantes",
    "crumbs": [
      "Général",
      "Consignes Projet 2"
    ]
  },
  {
    "objectID": "CMI-BDD.html",
    "href": "CMI-BDD.html",
    "title": "Bases de données",
    "section": "",
    "text": "Général :\n\ndatagouv: répertoire public français\ndatagov US: répertoire public américain\ndatagov UK: répertoire public anglais\nkaggle: répertoire public pour data science\nTidyTuesday: projets collaboratifs de la Data Science Learning Community.\nOpenintro: données éducatives\n\nStatistiques publiques :\n\nDBnomics ou voir le package R dbnomics\nOCDE ou voir le package R ocde\nEurostat ou voir le package R eurostat\n\nDonnées socioéconomiques :\n\nDonnées du livre de Cagé & Piketty: données à la maille commune sur les revenus, education, résultats électoraux…\n\nDonnées SIG :\n\nIGN\nNatural Earth\n\nDonnées Energie/environnement :\n\nSDES (Ministère Transition Ecologique).\nODRE (réseaux d’énergie).\nEEA (Agence européenne de l’environnement).\nDonnées incendies.\nDonnées prix carburants.",
    "crumbs": [
      "Général",
      "Bases de données"
    ]
  },
  {
    "objectID": "CMI-CN-intro.html",
    "href": "CMI-CN-intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Le cours en résumé :\n\n24 h\nObjectifs : prise en main de R et markdown, statistiques descriptives, graphiques\nLangage : R & Power BI (introduction si a le temps)\nModalités d’examens :\nNote de participation\nUn projet commun calcul numérique/économétrie avec choix du sujet libre\nPrésentation individuelle d’un chapitre d’un livre sur les bonnes pratiques de la dataviz : (Fundamentals of Data Visualization) de Clause Wilke. Inscription (ici).\n\nLe plan :\n\nCommandes des bases de R\nLes tableaux de données en R\nLes graphiques",
    "crumbs": [
      "Calcul Numérique",
      "Introduction"
    ]
  },
  {
    "objectID": "CMI-CN-TP1.html",
    "href": "CMI-CN-TP1.html",
    "title": "TP1 : Commandes de base de R",
    "section": "",
    "text": "1. Manipulation de vecteurs\nSoit le vecteur \\(x = (1, 2, 3, 4, 5)\\)",
    "crumbs": [
      "Calcul Numérique",
      "TP1 : Commandes de base de R"
    ]
  },
  {
    "objectID": "CMI-CN-TP1.html#manipulation-de-vecteurs",
    "href": "CMI-CN-TP1.html#manipulation-de-vecteurs",
    "title": "TP1 : Commandes de base de R",
    "section": "",
    "text": "Créer ce vecteur dans R et le stocker dans un objet que l’on appellera x ;\nAfficher le mode de x, puis sa longueur ;\nExtraire le premier élément, puis le dernier ;\nExtraire les trois premier éléments et les stocker dans un vecteur que l’on nommera a\nExtraire les éléments en position 1, 3, 5 ; les stocker dans un vecteur que l’on nommera b\nAdditionner le nombre 10 au vecteur x, puis multiplier le résultat par 2 ;\nEffectuer l’addition de a et b, commenter le résultat ;\nEffectuer l’addition suivante : x+a, commenter le résultat, puis regarder le résultat de a+x ;\nMultiplier le vecteur x par le scalaire c que l’on fixera à 2 ;\nEffectuer la multiplication de a et b, commenter le résultat ;\nEffectuer la multiplication suivante : x*a, commenter le résultat ;\nRécupérer les positions des multiples de 2 du vecteur x et les stocker dans un vecteur que l’on nommera ind, puis conserver uniquement les multiples de 2 de x dans un vecteur que l’on nommera mult_2 ;\nAfficher les éléments de x qui sont multiples de 3 et multiples de 2 ;\nAfficher les éléments de x qui sont multiples de 3 ou multiples de 2 ;\nCalculer la somme des éléments de x ;\nRemplacer le premier élément de x par un 4 ;\nRemplacer le premier élément de x par la valeur NA, puis calculer la somme des éléments de x;\nLister les objets en mémoire dans la session R ;\nSupprimer le vecteur a;\nSupprimer la totalité des objets de la session.",
    "crumbs": [
      "Calcul Numérique",
      "TP1 : Commandes de base de R"
    ]
  },
  {
    "objectID": "CMI-CN-TP1.html#manipulation-de-listes",
    "href": "CMI-CN-TP1.html#manipulation-de-listes",
    "title": "TP1 : Commandes de base de R",
    "section": "2. Manipulation de listes",
    "text": "2. Manipulation de listes\n\nÉvaluer le code suivant : TRUE+FALSE+TRUE*4 et le commenter ;\nÉvaluer les expressions suivantes : c(1, 4, TRUE), et c(1, 4, TRUE, \"bonjour\"), commenter ;\nCréer une liste que l’on appellera l et qui contient les éléments 1, 4 et TRUE en première, seconde et troisième positions respectivement ;\nExtraire le premier élément de la liste l, et afficher son mode. En faire de même avec le troisième élément, et commenter ;\nAjouter un quatrième élément à la liste l : “bonjour”, puis afficher la structure de l ;\nRetirer le troisième élément de la liste l ;\nCréer une liste de trois éléments : votre nom, votre prénom, et votre année de naissance. Ces trois éléments de la liste devront être nommés respectivement \"nom\", \"prenom\" et année de naissance. Stocker la liste ainsi créée dans un objet nommé moi ;\nExtraire le prénom de la liste moi de deux manières : en utilisant l’indice, et en utilisant le nommage ;\nCréer une liste avec la même structure que celle de moi, en la remplissant avec les informations d’une autre personne et la nommer toi Puis, créer la liste personnes, qui contiendra les listes toi et moi ;\nExtraire la liste toi de personnes (en première position) ;\nExtraire directement depuis personnes le prénom de l’élément en première position.",
    "crumbs": [
      "Calcul Numérique",
      "TP1 : Commandes de base de R"
    ]
  },
  {
    "objectID": "CMI-CN-TP1.html#manipulation-de-matrices",
    "href": "CMI-CN-TP1.html#manipulation-de-matrices",
    "title": "TP1 : Commandes de base de R",
    "section": "3. Manipulation de matrices",
    "text": "3. Manipulation de matrices\n\nCréer la matrice suivante : \\[ A =\n\\begin{bmatrix}\n-3 & 5 & 6 \\\\\n-1 & 2 & 2 \\\\\n1 & -1 & -1\n\\end{bmatrix}\n\\] ;\nAfficher la dimension de A, son nombre de colonnes, son nombre de lignes et sa longueur ;\nExtraire la seconde colonne de A, puis la première ligne ;\nExtraire l’élément en troisième position à la première ligne ;\nExtraire la sous-matrice de dimension 2 x 2 du coin inférieur de \\(A\\)\nCalculer la somme des colonnes puis des lignes de \\(A\\)\nAfficher la diagonale de A ;\nRajouter le vecteur colonne (1, 2 , 3) à droite de la matrice \\(A\\) et stocker le résultat dans un objet appelé \\(B\\) ;\nRetirer le quatrième vecteur de \\(B\\) ;\nRetirer la première et la troisième ligne de \\(B\\) ;\nAjouter le scalaire 10 à \\(A\\) ;\nAjouter le vecteur colonne (1 2 3) à \\(A\\) ;\nAjouter la matrice identité \\(I_3\\) à \\(A\\) ;\nDiviser tous les éléments de la matrice \\(A\\) par 2 ;\nMultiplier la matrice \\(A\\) par le vecteur colonne (1 2 3) ;\nAfficher la transposée de \\(A\\) ;\nEffectuer le produit avec transposition \\(A ^t A\\).",
    "crumbs": [
      "Calcul Numérique",
      "TP1 : Commandes de base de R"
    ]
  },
  {
    "objectID": "CMI-CN-TP1.html#manipulation-de-chaînes-de-caractères",
    "href": "CMI-CN-TP1.html#manipulation-de-chaînes-de-caractères",
    "title": "TP1 : Commandes de base de R",
    "section": "4. Manipulation de chaînes de caractères",
    "text": "4. Manipulation de chaînes de caractères\nCharger le package tidyverse, qui contient le package stringr.\n\nCréer les objets a et b afin qu’il contiennent respectivement les chaînes de caractères suivantes : 23 à 0 et C’est la piquette, Jack!;\nCréer le vecteur phrases de longueur 2, dont les deux éléments sont a et b ;\nÀ l’aide de la fonction appropriée dans le package stringr, afficher le nombre de carac- tètres de a, de b, puis appliquer la même fonction à l’objet phrases ;\nEn utilisant la fonction str_c(), concaténer a et b dans une seule chaîne de caractères, en choisissant la virgule comme caractère de séparation ;\nConcaténer les deux éléments du vecteur phrases en une seule chaine de caractères, en les séparant par le caractère de retour à la ligne , puis utiliser la fonction cat() pour afficher le résultat ;\nAppliquer la même fonction que dans la question précédente à l’objet suivant : c(NA, phrases) et commenter ;\nMettre en majuscules, puis en minuscules les chaînes du vecteur phrases (afficher le résultat, ne pas modifier phrases) ;\nÀ l’aide de la fonction word() du package stringr, extraire le mot la, puis Jack de la chaîne b ;\nMême question que la précédente, en utilisant la fonction str_sub() ;\nÀ l’aide de la fonction str_detect(), rechercher si le motif piqu puis mauvais sont présents dans b ;\nÀ l’aide de la fonction str_detect(), rechercher si le motif piqu est présent dans les éléments du vecteur phrases ;\nÀ l’aide de la fonction str_detect(), rechercher si le motif piqu ou le motif à sont présents dans les éléments du vecteur phrases ;\nEn utilisant la fonction str_locate(), retourner les positions de la première occurence du caractère a dans la chaîne b, puis essayer avec le caractère w pour observer le résultat retourné ;\nRetourner toutes les positions du motif a dans la chaîne b ;\nEn utilisant la fonction str_replace(), remplacer la première occurence du motif a, par le motif Z (afficher le résultat, ne pas modifier phrases) ;\nRemplacer toutes les occurences de a par Z dans la chaîne b (afficher le résultat, ne pas modifier phrases) ;\nUtiliser la fonction str_split() pour séparer la chaîne b en utilisant la virgule comme séparateur de sous-chaînes ;\nRetirer tous les caractères de ponctuation de la chaîne b, puis utiliser la fonction tr_trim() sur le résultat pour retirer les caractères blancs du début et de la fin de la chaîne.",
    "crumbs": [
      "Calcul Numérique",
      "TP1 : Commandes de base de R"
    ]
  },
  {
    "objectID": "CMI-CN-TP2.html",
    "href": "CMI-CN-TP2.html",
    "title": "TP2 : Tableaux de données",
    "section": "",
    "text": "1. Les verbes de base de dplyr\nOn commence par charger les extensions et les données nécessaires.\nExercice 1.1\nSélectionner la dixième ligne du tableau des aéroports (airports).\nSélectionner les 5 premières lignes de la table airlines.\nSélectionner l’aéroport avec l’altitude la plus basse.\nExercice 1.2\nSélectionnez les vols du mois de juillet (variable month).\nSélectionnez les vols avec un retard à l’arrivée (variable arr_delay) compris entre 5 et 15 minutes.\nSélectionnez les vols des compagnies Delta, United et American (codes DL, UA et AA de la variable carrier).\nExercice 1.3\nTriez la table flights par retard au départ décroissant.\nExercice 1.4\nSélectionnez les colonnes name, lat et lon de la table airports\nSélectionnez toutes les colonnes de la table airports sauf les colonnes tz et tzone\nSélectionnez toutes les colonnes de la table flights dont les noms se terminent par “delay”.\nDans la table airports, renommez la colonne alt en altitude et la colonne tzone en fuseau_horaire.\nExercice 1.5\nDans la table airports, la colonne alt contient l’altitude de l’aéroport en pieds. Créer une nouvelle variable alt_m contenant l’altitude en mètres (on convertit des pieds en mètres en les divisant par 3.2808). Sélectionner dans la table obtenue uniquement les deux colonnes alt et alt_m.",
    "crumbs": [
      "Calcul Numérique",
      "TP2 : Tableaux de données"
    ]
  },
  {
    "objectID": "CMI-CN-TP2.html#enchaîner-des-opérations",
    "href": "CMI-CN-TP2.html#enchaîner-des-opérations",
    "title": "TP2 : Tableaux de données",
    "section": "2. Enchaîner des opérations",
    "text": "2. Enchaîner des opérations\nExercice 2.1\nRéécrire le code de l’exercice précédent en utilisant le pipe %&gt;%.\n\n\n\nExercice 2.2\nEn utilisant le pipe, sélectionnez les vols à destination de San Francico (code SFO de la variable dest) et triez-les selon le retard au départ décroissant (variable dep_delay).\n\n\n\nExercice 2.3\nSélectionnez les vols des mois de septembre et octobre, conservez les colonnes dest et dep_delay, créez une nouvelle variable retard_h contenant le retard au départ en heures, et conservez uniquement les 5 lignes avec les plus grandes valeurs de retard_h.\n\n\n\n\ngroup_by et summarise\nExercice 3.1\nAffichez le nombre de vols par mois.\n\n\n\nTriez la table résultat selon le nombre de vols croissant.\n\n\n\nExercice 3.2\nCalculer la distance moyenne des vols selon l’aéroport de départ (variable origin).\n\n\n\nExercice 3.3\nCalculer le nombre de vols à destination de Los Angeles (code LAX) pour chaque mois de l’année.\n\n\n\nExercice 3.4\nCalculer le nombre de vols selon le mois et la destination.\n\n\n\nNe conserver, pour chaque mois, que la destination avec le nombre maximal de vols.\n\n\n\nExercice 3.5\nCalculer le nombre de vols selon le mois. Ajouter une colonne comportant le pourcentage de vols annuels réalisés par mois.\n\n\n\nExercice 3.6\nCalculer, pour chaque aéroport de départ et de destination, la durée moyenne des vols (variable air_time). Pour chaque aéroport de départ, ne conserver que la destination avec la durée moyenne la plus longue.",
    "crumbs": [
      "Calcul Numérique",
      "TP2 : Tableaux de données"
    ]
  },
  {
    "objectID": "CMI-CN-TP2.html#jointures",
    "href": "CMI-CN-TP2.html#jointures",
    "title": "TP2 : Tableaux de données",
    "section": "3. Jointures",
    "text": "3. Jointures\nExercice 4.1\nFaire la jointure de la table airlines sur la table flights à l’aide de left_join.\n\n\n\nExercice 4.2\nÀ partir de la table résultat de l’exercice précédent, calculer le retard moyen au départ pour chaque compagnie, et trier selon ce retard décroissant.\n\n\n\nExercice 4.3\nFaire la jointure de la table airports sur la table flights en utilisant comme clé le code de l’aéroport de destination.\n\n\n\nÀ partir de cette table, afficher pour chaque mois le nom de l’aéroport de destination ayant eu le plus petit nombre de vol.\n\n\n\nExercice 4.4\nCréer une table indiquant, pour chaque vol, uniquement le nom de l’aéroport de départ et celui de l’aéroport d’arrivée.",
    "crumbs": [
      "Calcul Numérique",
      "TP2 : Tableaux de données"
    ]
  },
  {
    "objectID": "CMI-CN-TP2.html#bonus",
    "href": "CMI-CN-TP2.html#bonus",
    "title": "TP2 : Tableaux de données",
    "section": "4. Bonus",
    "text": "4. Bonus\nExercice 5.1\nCalculer le nombre de vols selon l’aéroport de destination, et fusionnez la table airports sur le résultat avec left_join. Stocker le résultat final dans un objet nommé flights_dest.",
    "crumbs": [
      "Calcul Numérique",
      "TP2 : Tableaux de données"
    ]
  },
  {
    "objectID": "CMI-CN-TP3.html",
    "href": "CMI-CN-TP3.html",
    "title": "TP3 : Premiers Graphiques",
    "section": "",
    "text": "Exercice 1",
    "crumbs": [
      "Calcul Numérique",
      "TP3 : Premiers Graphiques"
    ]
  },
  {
    "objectID": "CMI-CN-TP3.html#exercice-1",
    "href": "CMI-CN-TP3.html#exercice-1",
    "title": "TP3 : Premiers Graphiques",
    "section": "",
    "text": "Avant toute chose, charger tidyverse. Charger aussi le jeu de données rp2018 dans le package questionr. Assigner un dataframe rp69 comme la restriction de rp2018 aux départements du Rhône et de la Loire. Faire un nuage de points croisant le pourcentage de sans diplôme (dipl_aucun) et le pourcentage d’ouvriers (ouvr).\n\n\n\n\n\nFaire un nuage de points croisant le pourcentage de sans diplôme et le pourcentage d’ouvriers, avec les points en rouge et de transparence 0.2.\n\n\n\n\n\nReprésenter la répartition du pourcentage de propriétaires (variable proprio) selon la taille de la commune en classes (variable pop_cl) sous forme de boîtes à moustaches.\n\n\n\n\n\nReprésenter la répartition du nombre de communes selon la taille de la commune en classes sous la forme d’un diagramme en bâtons.\n\n\n\n\n\nFaire un nuage de points croisant le pourcentage de sans diplôme et le pourcentage d’ouvriers. Faire varier la couleur selon le département (departement).\n\n\n\n\n\nSur le même graphique, faire varier la taille des points selon la population totale de la commune (pop_tot).\n\n\n\n\n\nEnfin, toujours sur le même graphique, rendre les points transparents en plaçant leur opacité à 0.5.\n\n\n\n\n\nReprésenter la répartition du pourcentage de propriétaires (variable proprio) selon la taille de la commune en classes (variable pop_cl) sous forme de boîtes à moustaches. Faire varier la couleur de remplissage (attribut fill) selon le département.\n\n\n\n\n\nReprésenter la répartition du nombre de communes selon la taille de la commune en classes (variable pop_cl) sous forme de diagramme en bâtons empilés, avec une couleur différente selon le département.\n\n\n\n\n\nFaire varier la valeur du paramètre position pour afficher les barres les unes à côté des autres.\n\n\n\n\n\nChanger à nouveau la valeur du paramètre position pour représenter les proportions de communes de chaque département pour chaque catégorie de taille.\n\n\n\n\n\nFaire un nuage de points représentant en abscisse le pourcentage de cadres (cadres) et en ordonnée le pourcentage de diplômés du supérieur (dipl_sup). Représenter ce nuage par deux graphiques différents selon le département en utilisant facet_grid.\n\n\n\n\n\nSur le même graphique, faire varier la taille des points selon la population totale de la communes (variable pop_tot) et rendre les points transparents.\n\n\n\n\n\nFaire le nuage de points croisant pourcentage de chômeurs (chom) et pourcentage de sans diplôme. Y ajouter les noms des communes correspondant (variable commune), en rouge et en taille 2.5 :\n\n\n\n\n\nDans le graphique précédent, n’afficher que le nom des communes ayant plus de 15% de chômage.",
    "crumbs": [
      "Calcul Numérique",
      "TP3 : Premiers Graphiques"
    ]
  },
  {
    "objectID": "CMI-CN-TP3.html#exercice-2",
    "href": "CMI-CN-TP3.html#exercice-2",
    "title": "TP3 : Premiers Graphiques",
    "section": "Exercice 2",
    "text": "Exercice 2\nAvant tout, charger le package tidyverse.\n\nUtiliser la fonction data() pour charger en mémoire le jeu de données economics. Consulter la page d’aide de ce jeu de données pour prendre connaissance de son contenu ;\nÀ l’aide de la fonction ggplot(), représenter les dépenses personnelles de consommation (pce) en fonction de la date (date). Les observations doivent être connectées par une ligne.\nModifier le graphique de la question précédente de manière à ce que la couleur de la ligne soit dodger blue et définir la taille de la ligne à 0.5. Stocker le résultat dans un objet que l’on appellera p_1 ;\nAjouter une couche au graphique p_1 pour modifier les titres des axes (les retirer), et définir le titre suivant : “Personal Consumption Expenditures (billions dollars)”.\nUtiliser la fonction scale_x_date() du package scales pour modifier l’échelle des abscisses de p_1, afin que les étiquettes des marques soient affichées tous les 5 ans ;\nA l’aide de l’option date_labels() de la fonction précédente, modifier le format de ces étiquettes pour que seule l’année des dates s’affiche ;",
    "crumbs": [
      "Calcul Numérique",
      "TP3 : Premiers Graphiques"
    ]
  },
  {
    "objectID": "CMI-CN-TP3.html#exercice-3",
    "href": "CMI-CN-TP3.html#exercice-3",
    "title": "TP3 : Premiers Graphiques",
    "section": "Exercice 3",
    "text": "Exercice 3\n\nUtiliser la fonction data() pour charger en mémoire le jeu de données economics. Consulter la page d’aide de ce jeu de données pour prendre connaissance de son contenu ;\nSélectionner les variables date,psavert et uempmed dans le tableau de données economics et utiliser la fonction gather() sur le résultat pour obtenir un tableau dans lequel chaque ligne indiquera la valeur (value) pour une variable donnée (key) à une date donnée (date). Stocker le résultat dans un objet que l’on appellera df ;\nSur un même graphique, représenter à l’aide de lignes, l’évolution dans le temps du taux d’épargne personnelle (psavert) et de la durée médiane en semaines du chômage (uempmed). Stocker le graphique dans un objet que l’on appellera p_2 ;\nModifier le code ayant servi à construire le graphique p_2 pour que le type de ligne soit différent pour chacune des deux séries représentées. Les deux lignes doivent être tracées en bleu. Stocker le graphique dans un objet que l’on appellera p_3 ;\nÀ présent, modifier le code ayant servi à construire p_3 pour qu’à la fois la couleur et le type de ligne servent à différencier les deux séries. Stocker le graphique dans un objet que l’on appellera p_4 ;\nModifier le graphique p_4 en ajoutant une couche d’échelle de couleur pour que le taux d’épargne personnelle (psavert) soit représenté en dodger blue, et que la durée de chômage (uempmed) soit représentée en rouge. Par ailleurs, retirer le titre de la légende ;\nModifier le graphique p_4 en ajoutant une couche d’échelle de type de ligne pour que le taux d’épargne personnelle (psavert) soit représenté par des tirets, et que la durée de chômage (uempmed) soit représentée par une ligne pleine. Par ailleurs, retirer le titre de la légende des types de lignes, afin que les légendes de couleur et de type de ligne soient fusionnées ;\nCréer le tableaux de données df_2, une copie de df, dans lequel la variable key doit être un facteur dont les niveaux sont uempmed et psavert ;\nCréer le vecteur etiq suivant etiq &lt;- c(\"psavert\" = \"Pers. Saving Rate\",\"uempmed\" = \"Median Duration of Unemployment (weeks)\") Ce vecteur contient des valeurs d’étiquettes pour la légende du graphique qu’il va falloir créer. Représenter sur un même graphique l’évolution dans le temps du taux d’épargne personnelle et de la durée médiane du chômage en semaines, en s’appuyant sur les données contenues dans le tableau df_2. La courbe du taux d’épargne personnelle doit être composée de tirets et être de couleur dodger blue; la courbe de la durée médiane du taux de chômage doit être une ligne rouge. La légende ne doit pas comporter de titre, et ses étiquettes doivent être modifiées pour que “Pers. Saving Rate” s’affiche ’a la place de “psavert”, et pour que “Median Duration of Unemployment (weeks)” s’affiche à la place de “uempmed”. Stocker le graphique dans un objet que l’on appellera p_5 ; Note : il s’agit de reprendre le code ayant servi à créer le graphique p_4, en modifiant légèrement les échelles de couleur et de ligne pour prendre en compte les étiquettes proposées dans le vecteur etiq.\nModifier p_5 pour lui ajouter une couche permettant de déplacer la légende en bas du graphique (utiliser la fonction theme()) ;\nAjouter une couche au graphique p_5 qui permet de définir un thème. Utiliser le thème minimal (theme_minimal()). Que se passe-t-il pour la légende ? Repositionner la légende en dessous, et retirer les titres des axes ;\nSauvegarder le graphique p_5 au format PDF en précisant une largeur de 12 et une hauteur de 8.",
    "crumbs": [
      "Calcul Numérique",
      "TP3 : Premiers Graphiques"
    ]
  },
  {
    "objectID": "CMI-CN-TP3.html#exercice-4",
    "href": "CMI-CN-TP3.html#exercice-4",
    "title": "TP3 : Premiers Graphiques",
    "section": "Exercice 4",
    "text": "Exercice 4\n\nCharger le jeu de données mpg contenu dans lepackage ggplot2 en mémoire, puis consulter la page d’aide du jeu de données pour en prendre connaissance ;\nReprésenter à l’aide d’un nuage de points la relation entre la consommation sur autoroute des véhicules de l’échantillon (hwy) et la cylindrée de leur moteur (displ)\nReprendre le code du graphique précédent et modifier la forme des points pour les changer en symbole +; modifier la couleur des + de manière à la faire dépendre du nombre de cylindres (cyl) ;\nÀ présent, représenter par des boîtes à moustaches la distribution de la consommation sur autoroute des véhicules (hwy) pour chacune des valeurs possibles du nombre de cylindres (cyl) ;\nCharger le jeu de données economics contenu dans le package ggplot2 en mémoire, puis consulter la page d’aide du jeu de données pour en prendre connaissance. Ensuite, ajouter au tableau (les créer) les variables u_rate et e_rate, respectivement le taux de chômage et le taux d’emploi (on définira le taux de chômage de manière très grossière ici : nombre de personnes non employées sur la population totale) ;\nReprésenter à l’aide de barres l’évolution dans le temps du taux de chômage, et remplir les barres avec la couleur rouge ;\nReprendre le code du graphique précédent et ajouter une couche permettant de modifier les limites de l’axe des abscisses pour afficher les valeurs uniquement sur la période “2012- 01-01” à “2015-01-01” (utiliser la fonction coord_cartesian()). Stocker le graphique dans un objet que l’on appellera p ;\nDans le tableau de données economics, sélectionner les variables date, u_rate et e_rate, puis utiliser la fonction gather() pour obtenir un tableau dans lequel chaque ligne correspond à la valeur d’une des variables (taux de chômage ou taux d’emploi) à une date donnée. Stocker le résultat dans un objet que l’on appellera df_3 ;\nUtiliser le tableau de données df_3 pour représenter graphiquement à l’aide de barres les taux de chômage et taux d’emploi par mois sur la période “2012-01-01” à “2015-01-01”. Sur le graphique, les barres représentant le taux de chômage et celles représentant le taux d’emploi devront être superposées. Note : il s’agit de modifier légèrement le code ayant permis de réaliser le graphique p.",
    "crumbs": [
      "Calcul Numérique",
      "TP3 : Premiers Graphiques"
    ]
  },
  {
    "objectID": "CMI-CN-TP3.html#exercice-5",
    "href": "CMI-CN-TP3.html#exercice-5",
    "title": "TP3 : Premiers Graphiques",
    "section": "Exercice 5",
    "text": "Exercice 5\n\nÀ l’aide de la fonction WDI du package WDI, récupérer la série fournie par la Banque Mondiale du PIB par tête (NY.GDP.PCAP.PP.KD) pour tous les pays disponibles pour l’année 2010, et stocker ces données dans un tableau que l’on appellera gdp_capita ;\nDans le tableau gdp_capita, modifier la valeur de la variable country pour l’observation de la Slovaquie, pour qu’elle vaille Slovakia au lieu de Slovak Republic ;\nFiltrer les observations du tableau gdp_capita pour ne conserver que les observations des pays membres de l’Union Européenne dont les noms sont contenus dans le vecteur membres_ue. Stocker le résultat dans un tableau que l’on nommera gdp_capita_eu ;\n\n\nUtiliser le package rworldmap pour récupérer les données nécessaires à la réalisation d’une carte du monde ;\nAfficher une carte du monde à l’aide des fonctions contenues dans le package ggplot2 ;\nModifier les échelles des axes pour faire figurer les méridiens de -60 à 60 par pas de 30 et les parallèles de -180 à 180 par pas de 45. Modifier également la projection cartographique pour choisir la projection orthographique, à l’aide de la fonction coord_map() ;\nJoindre les informations contenues dans le tableau gdp_capita_eu au tableau contenant les données permettant la réalisation des cartes ;\nRéaliser une carte choroplèthe reflétant pour chaque pays membre de l’Union Européenne la valeur du PIB par tête de 2012 ;\nModifier les couleurs de l’échelle continue de la carte précédente, pour que les faibles valeurs du PIB par tête soient représentées en jaune, et les valeurs les plus hautes en rouge ;\nModifier les ruptures de l’échelle de couleur pour qu’elles aillent de 10000 à 100000; modifier également l’étiquette de ces ruptures de sorte que 35000 soit affiché comme 35k, 60000 comme 60k, etc. Enfin, ajouter un titre au graphique et retirer les titres d’axes.",
    "crumbs": [
      "Calcul Numérique",
      "TP3 : Premiers Graphiques"
    ]
  },
  {
    "objectID": "CMI-CN-TP4.html",
    "href": "CMI-CN-TP4.html",
    "title": "TP4 : Fonctions et manipulation de données",
    "section": "",
    "text": "1. Mise en ordre des données\nPour reprendre la définition du manuel de Julien Barnier, le concept de tidy data repose sur trois règles interdépendantes. Des données sont considérées comme tidy si :\nDans cette partie, nous allons travailler sur les fonctions du package tidyr: pivot_longer(), pivot_wider(), separate() et unite().\nLes jeux de données utilisés (table1, table2, table3, table4a, table4b, table5) sont directement disponibles après avoir chargé tidyverse.\nlibrary(tidyverse)\n\ndata(table1)\ndata(table2)\ndata(table3)\ndata(table4a)\ndata(table4b)\ndata(table5)",
    "crumbs": [
      "Calcul Numérique",
      "TP4 : Fonctions et manipulation de données"
    ]
  },
  {
    "objectID": "CMI-CN-TP4.html#mise-en-ordre-des-données",
    "href": "CMI-CN-TP4.html#mise-en-ordre-des-données",
    "title": "TP4 : Fonctions et manipulation de données",
    "section": "",
    "text": "chaque ligne correspond à une observation\nchaque colonne correspond à une variable\nchaque valeur est présente dans une unique case de la table ou, de manière équivalente, des unités d’observations différentes sont présentes dans des tables différentes\n\n\n\n\n\n1.1 Représentations multiples d’un même jeu de données\nAvec table1, table2, et table3 On vous donne trois représentations du nombre de cas de tuberculose (TB) par pays et par année.\n\nAffichez les trois jeux de données et comparez leurs structures.\n\n\nQuelles différences remarquez-vous ?\nQuelles sont les variables présentes dans chacun ?\n\n\nParmi eux, lequel est déjà au format tidy ? Justifiez.\nTransformez table2 et table3 en jeux de données tidy comparables à table1. Indice : utilisez pivot_wider() et pivot_longer().\n\n\n\n1.2 Colonnes multiples représentant plusieurs variables\nLes tableaux table4a et table4b contiennent respectivement le nombre de cas et la population.",
    "crumbs": [
      "Calcul Numérique",
      "TP4 : Fonctions et manipulation de données"
    ]
  },
  {
    "objectID": "CMI-CN-TP4.html#fonctions-en-r",
    "href": "CMI-CN-TP4.html#fonctions-en-r",
    "title": "TP4 : Fonctions et manipulation de données",
    "section": "2. Fonctions en R",
    "text": "2. Fonctions en R\nEn R, la syntaxe des fonctions est la suivante:\n\najoute &lt;- function(x,y) {\n  res &lt;- x + y\n  return(res)\n}\n\n\n2.1 Introduction et exemples\nExercice 1.1\nÉcrire une fonction nommée perimetre qui prend en entrée un argument nommé r et retourne le périmètre d’un cercle de rayon r, c’est-à-dire 2 * pi * r (pi est un objet R qui contient la valeur de \\(\\pi\\)).\nVérifier avec l’appel suivant :\n\nperimetre(4)\n\n\n\nperimetre &lt;- function(r) {\n  resultat &lt;- 2 * pi * r\n  return(resultat)\n}\n\n\nExercice 1.2\nÉcrire une fonction etendue qui prend en entrée un vecteur numérique et retourne la différence entre la valeur maximale et la valeur minimale de ce vecteur.\nVérifier avec l’appel suivant :\n\netendue(c(18, 35, 21, 40))\n\n\n\netendue &lt;- function(v) {\n  vmax &lt;- max(v)\n  vmin &lt;- min(v)\n  return(vmax - vmin)\n}\n\n\nExercice 1.3\nÉcrire une fonction nommée alea qui accepte un argument n, génère un vecteur de n valeurs aléatoires entre 0 et 1 avec la fonction runif(n) et retourne ce vecteur comme résultat.\n\n\nalea &lt;- function(n) {\n  v &lt;- runif(n)\n  return(v)\n}\n\n\nModifier la fonction pour qu’elle accepte deux arguments supplémentaires min et max et qu’elle retourne un vecteur de n valeurs aléatoires comprises entre min et max avec la fonction runif(n, min, max).\n\n\nalea &lt;- function(n, min, max) {\n  v &lt;- runif(n, min, max)\n  return(v)\n}\n\n\nModifier à nouveau la fonction pour qu’elle retourne un vecteur de n nombres entiers aléatoires compris entre min et max en appliquant la fonction trunc() au vecteur généré par runif().\nVérifier le résultat avec :\n\nv &lt;- alea(10000, 1, 6)\ntable(v)\n\n\n\nalea &lt;- function(n, min, max) {\n  v &lt;- runif(n, min, max + 1)\n  v &lt;- trunc(v)\n  return(v)\n}\n\n\nExercice 1.4\nÉcrire une fonction nommée meteo qui prend un argument nommé ville avec le corps suivant :\n\nout &lt;- readLines(paste0(\"https://v2.wttr.in/\", ville, \"?A\"))\ncat(out, sep = \"\\n\")\n\nTester la fonction avec par exemple meteo(\"Lyon\") (il est possible que l’affichage dans la console ne soit pas lisible si vous travaillez sous Windows).\n\n\nmeteo &lt;- function(ville) {\n  out &lt;- readLines(paste0(\"https://v2.wttr.in/\", ville, \"?A\"))\n  cat(out, sep = \"\\n\")\n}\n\n\nExercice 1.5\nSoit le code suivant, qui recode une variable du jeu de données hdv2003 en utilisant str_to_lower() puis fct_recode() :\n\nlibrary(questionr)\nlibrary(tidyverse)\ndata(hdv2003)\n\nhdv2003$hard.rock &lt;- str_to_lower(hdv2003$hard.rock)\nhdv2003$hard.rock &lt;- fct_recode(hdv2003$hard.rock, \"o\" = \"oui\", \"n\" = \"non\")\n\nTransformer ce code en une fonction nommée recode_oui_non, et appliquer cette fonction à hard.rock, lecture.bd et cuisine.\n\n\nrecode_oui_non &lt;- function(var) {\n  var_rec &lt;- str_to_lower(var)\n  var_rec &lt;- fct_recode(var_rec, \"o\" = \"oui\", \"n\" = \"non\")\n  return(var_rec)\n}\n\nhdv2003$hard.rock &lt;- recode_oui_non(hdv2003$hard.rock)\nhdv2003$lecture.bd &lt;- recode_oui_non(hdv2003$lecture.bd)\nhdv2003$cuisine &lt;- recode_oui_non(hdv2003$cuisine)\n\n\n\n\n2.2 Arguments et résultat\nExercice 2.1\nObserver le code de la fonction suivante pour comprendre à quoi correspondent chacun de ses trois arguments, puis réordonner et renommer ces arguments de manière plus pertinente :\n\nmoyenne_arrondie &lt;- function(d, vecteur_contenant_les_donnees, supprimer_les_na) {\n  res &lt;- mean(vecteur_contenant_les_donnees, na.rm = supprimer_les_na)\n  res &lt;- round(res, d)\n  return(res)\n}\n\n\n\nmoyenne_arrondie &lt;- function(v, decimales, na.rm) {\n  res &lt;- mean(v, na.rm = na.rm)\n  res &lt;- round(res, decimales)\n  return(res)\n}\n\n\nDonner aux arguments de la fonction une valeur par défaut.\n\n\nmoyenne_arrondie &lt;- function(v, decimales = 2, na.rm = TRUE) {\n  res &lt;- mean(v, na.rm = na.rm)\n  res &lt;- round(res, decimales)\n  return(res)\n}\n\n\nSimplifier la fonction en utilisant la syntaxe plus compacte qui ne fait pas appel à return().\n\n\nmoyenne_arrondie &lt;- function(v, decimales = 2, na.rm = TRUE) {\n  res &lt;- mean(v, na.rm = na.rm)\n  round(res, decimales)\n}\n\n\nExercice 2.2\nSimplifier la fonction suivante pour que son corps ne fasse plus qu’une seule ligne :\n\ncentrer_reduire &lt;- function(x) {\n  res &lt;- x - mean(x)\n  res &lt;- res / sd(x)\n  return(res)\n}\n\n\n\ncentrer_reduire &lt;- function(x) {\n  (x - mean(x)) / sd(x)\n}\n\n\nExercice 2.3\nLe code suivant permet de déterminer la lettre initiale et la longueur d’un mot.\n\ninitiale &lt;- str_sub(mot, 1, 1)\nlongueur &lt;- nchar(mot)\n\nUtiliser ce code pour créer une fonction caracteristiques_mot() qui prend un argument mot et retourne à la fois son initiale et sa longueur.\n\ncaracteristiques_mot(\"Bidonnage\")\n\n\n\ncaracteristiques_mot &lt;- function(mot) {\n  initiale &lt;- str_sub(mot, 1, 1)\n  longueur &lt;- nchar(mot)\n  list(initiale = initiale, longueur = longueur)\n}\n\n\nFacultatif : modifier la fonction pour qu’elle retourne un vecteur plutôt qu’une liste, et l’appliquer sur un mot de votre choix. Que constatez-vous ?\n\nComme les vecteurs atomiques ne peuvent contenir que des données du même type, le nombre correspondant à longueur a été converti en chaîne de caractères.\n\n\n\n2.3 Portée des variables\nExercice 3.1\nEn lisant les codes suivants, essayer de prévoir quelle va être la valeur affichée par la dernière ligne. Vérifier en exécutant le code :\n\nf &lt;- function() {\n  x &lt;- 3\n  x\n}\n\nf()\n\n\nf &lt;- function() {\n  x\n}\n\nx &lt;- 5\nf()\n\n\nf &lt;- function(x) {\n  x\n}\n\nx &lt;- 5\nf(30)\n\n\nf &lt;- function(x = 100) {\n  x\n}\n\nx &lt;- 5\nf()\n\n\nf &lt;- function(x = 100) {\n  x &lt;- 150\n  x\n}\n\nx &lt;- 5\nf(30)\n\n\nf &lt;- function() {\n  x &lt;- 5\n}\n\nx &lt;- 1000\nf()\nx\n\nExercice 3.2\nDans le code suivant, on a essayé de créer une fonction qui modifie un tableau de données passé en argument pour ne conserver que les lignes correspondant aux pommes. Est-ce que ça fonctionne ?\n\ndf &lt;- data.frame(\n  fruit = c(\"Pomme\", \"Pomme\", \"Citron\", \"Citron\"),\n  poids = c(147, 189, 76, 91)\n)\n\nfiltre_pommes &lt;- function(d) {\n  d &lt;- dplyr::filter(d, fruit == \"Pomme\")\n}\n\nfiltre_pommes(df)\ndf\n\nModifier le code pour obtenir le résultat souhaité.\n\n\nfiltre_pommes &lt;- function(d) {\n  dplyr::filter(d, fruit == \"Pomme\")\n}\n\ndf &lt;- filtre_pommes(df)\ndf\n\n\n\n\n2.4 Les fonctions comme objets\nExercice 4.1\nÉcrire une fonction nommée bonjour qui ne prend aucun argument et affiche juste le texte “Bonjour !” dans la console.\n\n\nbonjour &lt;- function() {\n  cat(\"Bonjour !\")\n}\n\n\nExécuter dans la console les deux commandes suivantes tour à tour :\n\nbonjour()\nbonjour\n\nComprenez-vous la différence entre les deux ?\nCopier la fonction dans un nouvel objet nommé salut. Exécuter la nouvelle fonction ainsi créée.\n\n\nsalut &lt;- bonjour\nsalut()\n\n\nExercice 4.2\nConstruire une fonction etendue() qui prend en entrée un vecteur numérique et retourne la différence entre la valeur maximale et la valeur minimale de ce vecteur (vous pouvez récupérer le code de l’exercice 1.2).\n\n\netendue &lt;- function(v) {\n  max(v) - min(v)\n}\n\n\nÀ l’aide de tapply(), appliquez la fonction etendue() à la variable age pour chaque valeur de qualif dans le jeu de données hdv2003.\n\n\nlibrary(questionr)\ndata(hdv2003)\n\ntapply(hdv2003$age, hdv2003$qualif, etendue)\n\n\nRéécrire le code précédent en utilisant une fonction anonyme (ie en définissant la fonction directement dans le tapply).\n\n\ntapply(hdv2003$age, hdv2003$qualif, function(v) {\n  max(v) - min(v)\n})\n\n\nExercice 4.3\nExécutez le code suivant. Comprenez-vous les résultats obtenus ?\n\nf &lt;- function(y) {\n  y * 4\n}\n\nbody(f)\nf(5)\n\nbody(f) &lt;- quote(y + 2)\nbody(f)\nf(5)\n\nIntuitivement, comprenez-vous à quoi sert la fonction quote ?",
    "crumbs": [
      "Calcul Numérique",
      "TP4 : Fonctions et manipulation de données"
    ]
  },
  {
    "objectID": "CMI-CN-TP4.html#fonctions-et-dplyr",
    "href": "CMI-CN-TP4.html#fonctions-et-dplyr",
    "title": "TP4 : Fonctions et manipulation de données",
    "section": "3. Fonctions et Dplyr",
    "text": "3. Fonctions et Dplyr\nPour certains des exercices qui suivent on utilisera le jeu de données starwars. Le jeu de données contient les caractéristiques de 87 personnages présents dans les films : espèce, âge, planète d’origine, etc.\n\n3.1 Appliquer ses propres fonctions\nExercice 1.1\nCréer une fonction imc qui prend en argument un vecteur taille (en cm) et un vecteur poids (en kg) et retourne les valeurs correspondantes de l’indice de masse corporelle, qui se calcule en divisant le poids en kilos par la taille en mètres au carré.\n\n\nimc &lt;- function(tailles, poids) {\n    tailles_m &lt;- tailles / 100\n    poids / tailles_m ^ 2\n}\n\n\nUtiliser cette fonction pour ajouter une nouvelle variable imc au tableau starwars.\n\n\nstarwars %&gt;%\n    mutate(imc = imc(height, mass))\n\n\nÀ l’aide de group_by() et summarise(), utiliser à nouveau cette fonction pour calculer l’IMC moyen selon les valeurs de la variable species.\n\n\nstarwars %&gt;%\n    group_by(species) %&gt;%\n    summarise(\n        imc = mean(imc(height, mass), na.rm = TRUE)\n    )\n\n\nExercice 1.2\nToujours dans le jeu de données starwars, à l’aide d’un group_by() et d’un summarise(), calculer pour chaque valeur de la variable sex la valeur de l’étendue de la variable height du jeu de données starwars, c’est-à-dire la différence entre sa valeur maximale et sa valeur minimale.\n\n\nstarwars %&gt;%\n    group_by(sex) %&gt;%\n    summarise(\n        etendue_taille = max(height, na.rm = TRUE) - min(height, na.rm = TRUE)\n    )\n\n\nEn partant du code précédent, créer une fonction etendue qui prend en argument un vecteur et retourne la différence entre sa valeur maximale et sa valeur minimale. En utilisant cette fonction, calculer pour chaque valeur de sex la valeur de l’étendue des variables height et mass.\n\n\netendue &lt;- function(v) {\n    max(v, na.rm = TRUE) - min(v, na.rm = TRUE)\n}\nstarwars %&gt;%\n    group_by(sex) %&gt;%\n    summarise(\n        etendue_taille = etendue(height),\n        etendue_poids  = etendue(mass)\n    )\n\n\nExercice 1.3\nOn a vu que la fonction suivante permet de calculer le pourcentage des éléments d’un vecteur de chaînes de caractères se terminant par un suffixe passé en argument.\n\nprop_suffixe &lt;- function(v, suffixe) {\n    # On ajoute $ à la fin du suffixe pour capturer uniquement en fin de chaîne\n    suffixe &lt;- paste0(suffixe, \"$\")\n    # Détection du suffixe\n    nb_detect &lt;- sum(str_detect(v, suffixe))\n    # On retourne le pourcentage\n    nb_detect / length(v) * 100\n}\n\nModifier cette fonction en une fonction prop_prefixe qui retourne le pourcentage d’éléments commençant par un préfixe passé en argument. Indication : pour détecter si une chaîne commence par \"ker\", on utilise l’expression régulière \"^ker\".\n\n\nprop_prefixe &lt;- function(v, prefixe) {\n    # On ajoute $ à la fin du prefixe pour capturer uniquement en début de chaîne\n    prefixe &lt;- paste0(\"^\", prefixe)\n    # Détection du motif\n    nb_detect &lt;- sum(str_detect(v, prefixe))\n    # On retourne le pourcentage\n    nb_detect / length(v) * 100\n}\n\n\nUtiliser prop_prefixe dans un summarise appliqué à rp2018 pour calculer le pourcentage de communes commençant par “Saint” selon le département. Ordonner les résultats par pourcentage décroissant.\n\n\nrp2018 %&gt;%\n    group_by(departement) %&gt;%\n    summarise(\n        prop_saint = prop_prefixe(commune, \"Saint\")\n    ) %&gt;%\n    arrange(desc(prop_saint))\n\n\nCréer une fonction tab_prefixe qui prend un seul argument prefixe et renvoie le tableau obtenu à la question précédente pour le préfixe passé en argument. Tester avec tab_prefixe(\"Plou\") et tab_prefixe(\"Sch\")\n\n\ntab_prefixe &lt;- function(prefixe) {\n    rp2018 %&gt;%\n        group_by(departement) %&gt;%\n        summarise(\n            prop = prop_prefixe(commune, prefixe)\n        ) %&gt;%\n        arrange(desc(prop))\n}\n\n\nExercice 1.4\nLe vecteur suivant donne, pour chacun des neuf principaux films de la saga Star Wars, la date à laquelle ils se déroulent dans l’univers de la saga.\n\nc(\n    \"I\"    = -32,\n    \"II\"   = -22,\n    \"III\"  = -19,\n    \"IV\"   =   0,\n    \"V\"    =   3,\n    \"VI\"   =   4,\n    \"VII\"  =  34,\n    \"VIII\" =  34,\n    \"IX\"   =  35\n)\n\nDans le jeu de données starwars, la variable birth_year indique l’année de naissance du personnage en “années avant l’an zéro” (une valeur de 19 signifie donc une année de naissance de -19).\nCréer une fonction age_film qui prend en entrée un vecteur d’années de naissance au même format que birth_year ainsi que l’identifiant d’un film, et calcule les âges à la date du film.\nVérifier avec :\n\nage_film(starwars$birth_year, \"IV\")\n\n\n\nage_film &lt;- function(annees, film) {\n    annees_films &lt;- c(\n        \"I\"    = -32,\n        \"II\"   = -22,\n        \"III\"  = -19,\n        \"IV\"   =   0,\n        \"V\"    =   3,\n        \"VI\"   =   4,\n        \"VII\"  =  34,\n        \"VIII\" =  34,\n        \"IX\"   =  35\n    )\n    annees_naissance &lt;- -annees\n    annee_ref &lt;- annees_films[film]\n    annee_ref - annees_naissance\n}\n\n\nUtiliser la fonction pour ajouter deux nouvelles variables au tableau starwars : age_iv qui correspond à l’âge (potentiel) au moment du film IV, et age_ix qui correspond à l’âge au moment du film IX.\n\n\nstarwars %&gt;%\n    mutate(\n        age_iv = age_film(birth_year, \"IV\"),\n        age_ix = age_film(birth_year, \"IX\"),\n    )\n\n\n\n\n3.2 across()\nExercice 2.1\nReprendre la fonction etendue de l’exercice 1.2 :\n\netendue &lt;- function(v) {\n    max(v, na.rm = TRUE) - min(v, na.rm = TRUE)\n}\n\nDans le jeu de données starwars, calculer l’étendue des variables height et mass pour chaque valeur de sex à l’aide de group_by(), summarise() et across().\n\n\nstarwars %&gt;%\n    group_by(sex) %&gt;%\n    summarise(\n        across(\n            c(height, mass),\n            etendue\n        )\n    )\n\n\nToujours à l’aide d’across(), appliquer etendue à toutes les variables numériques, toujours pour chaque valeur de sex.\n\n\nstarwars %&gt;%\n    group_by(sex) %&gt;%\n    summarise(\n        across(\n            where(is.numeric),\n            etendue\n        )\n    )\n\n\nEn utilisant & et !, appliquer etendue à toutes les variables numériques sauf à celles qui finissent par “year”.\n\n\nstarwars %&gt;%\n    group_by(sex) %&gt;%\n    summarise(\n        across(\n            where(is.numeric) & !ends_with(\"year\"),\n            etendue\n        )\n    )\n\n\nExercice 2.2\nDans le jeu de données starwars, appliquer en un seul summarise les fonctions min et max aux variables height et mass.\n\n\nstarwars %&gt;%\n    summarise(\n        across(\n            c(height, mass),\n            list(min = min, max = max)\n        )\n    )\n\n\nSi vous ne l’avez pas déjà fait à la question précédente, modifier le code pour que le calcul des valeurs minimales et maximales ne prennent pas en compte les valeurs manquantes.\n\n\nfuns &lt;- list(\n    min = function(v) { min(v, na.rm = TRUE) },\n    max = function(v) { max(v, na.rm = TRUE) }\n)\nstarwars %&gt;%\n    summarise(\n        across(\n            c(height, mass),\n            funs\n        )\n    )\n# Autre possibilité : les arguments supplémentaires passés à across() sont\n# transmis aux fonctions appliquées\nstarwars %&gt;%\n    summarise(\n        across(\n            c(height, mass),\n            list(min = min, max = max),\n            na.rm = TRUE\n        )\n    )\n\n\nExercice 2.3\nDans le jeu de données hdv2003, utiliser across() pour transformer les modalités “Oui” et “Non” en TRUE et FALSE pour toutes les variables de hard.rock à sport.\n\n\ndetecte_oui &lt;- function(v) {\n    v == \"Oui\"\n}\nhdv2003 %&gt;%\n    mutate(\n        across(\n            hard.rock:sport,\n            detecte_oui\n        )\n    )\n\n\nAjouter un argument .names à across() pour que les variables recodées soient stockées dans de nouvelles colonnes nommées avec le suffixe \"_true\".\n\n\ndetecte_oui &lt;- function(v) {\n    v == \"Oui\"\n}\nhdv2003 %&gt;%\n    mutate(\n        across(\n            hard.rock:sport,\n            detecte_oui,\n            .names = \"{.col}_true\"\n        )\n    )\n\n\n\n\n3.3 Fonctions anonymes et notations abrégées\nExercice 3.1\nDans un exercice précédent, on a vu que le code ci-dessous permet de calculer l’étendue des variables height et mass du jeu de données starwars.\n\netendue &lt;- function(v) {\n    max(v, na.rm = TRUE) - min(v, na.rm = TRUE)\n}\n\nstarwars %&gt;%\n    group_by(sex) %&gt;%\n    summarise(\n        across(\n            c(height, mass),\n            etendue\n        )\n    )\n\nModifier ce code en supprimant la définition de etendue et en utilisant à la place une fonction anonyme directement dans le across().\n\n\nstarwars %&gt;%\n    group_by(sex) %&gt;%\n    summarise(\n        across(\n            c(height, mass),\n            function(v) {\n               max(v, na.rm = TRUE) - min(v, na.rm = TRUE)\n            }\n        )\n    )\n\n\nModifier à nouveau ce code pour utiliser la syntaxe abrégée de type “formule” du tidyverse.\n\n\nstarwars %&gt;%\n    group_by(sex) %&gt;%\n    summarise(\n        across(\n            c(height, mass),\n            ~ max(.x, na.rm = TRUE) - min(.x, na.rm = TRUE)\n        )\n    )\n\n\nExercice 3.2\nSoit le code suivant, qui renomme les colonnes du tableau starwars de type liste en leur ajoutant le préfixe “liste_”.\n\najoute_prefixe_liste &lt;- function(nom) {\n    paste0(\"liste_\", nom)\n}\n\nstarwars %&gt;%\n    rename_with(ajoute_prefixe_liste, .cols = where(is.list))\n\nRéécrire ce code avec une fonction anonyme en utilisant les trois notations :\n\nclassique (avec function())\nformule (du tidyverse)\ncompacte (à partir de R 4.1)\n\n\n\n# Classique\nstarwars %&gt;%\n    rename_with(\n        function(nom) { paste0(\"liste_\", nom) },\n        .cols = where(is.list)\n    )\n# Formule\nstarwars %&gt;%\n    rename_with(\n        ~ paste0(\"liste_\", .x),\n        .cols = where(is.list)\n    )\n# Compacte\nstarwars %&gt;%\n    rename_with(\n        \\(nom) paste0(\"liste_\", nom),\n        .cols = where(is.list)\n    )\n\n\nExercice 3.3\nLe code suivant indique, pour chaque région du jeu de données rp2018, le nom de la commune ayant la valeur maximale pour les variables dipl_aucun et dipl_sup.\n\nnom_commune_max &lt;- function(valeurs, communes) {\n    communes[valeurs == max(valeurs)]\n}\n\nrp2018 %&gt;%\n    group_by(region) %&gt;%\n    summarise(\n        across(\n            c(dipl_aucun, dipl_sup),\n            nom_commune_max,\n            commune\n        )\n    )\n\nRéécrire ce code en utilisant une fonction anonyme, avec la syntaxe de votre choix (classique, formule ou compacte).\n\n\n# Classique\nrp2018 %&gt;%\n    group_by(region) %&gt;%\n    summarise(\n        across(\n            c(dipl_aucun, dipl_sup),\n            function(valeurs, communes) { communes[valeurs == max(valeurs)] },\n            commune\n        )\n    )\n# Formule\nrp2018 %&gt;%\n    group_by(region) %&gt;%\n    summarise(\n        across(\n            c(dipl_aucun, dipl_sup),\n            ~ .y[.x == max(.x)],\n            commune\n        )\n    )\n# Compacte\nrp2018 %&gt;%\n    group_by(region) %&gt;%\n    summarise(\n        across(\n            c(dipl_aucun, dipl_sup),\n            \\(valeurs, communes) communes[valeurs == max(valeurs)],\n            commune\n        )\n    )\n\n\nÀ l’aide d’une fonction anonyme supplémentaire, modifier le code pour qu’il retourne également, pour les mêmes variables, le nom des communes avec les valeurs minimales.\n\n\n# Formule\nrp2018 %&gt;%\n    group_by(region) %&gt;%\n    summarise(\n        across(\n            c(dipl_aucun, dipl_sup),\n            list(\n                max = ~ .y[.x == max(.x)],\n                min = ~ .y[.x == min(.x)]\n            ),\n            commune\n        )\n    )\n# Compacte\nrp2018 %&gt;%\n    group_by(region) %&gt;%\n    summarise(\n        across(\n            c(dipl_aucun, dipl_sup),\n            list(\n                max = \\(valeurs, communes) communes[valeurs == max(valeurs)],\n                min = \\(valeurs, communes) communes[valeurs == min(valeurs)]\n            ),\n            commune\n        )\n    ) %&gt;% View()\n\n\n\n\n3.4 rowwise() et c_across()\nExercice 4.1\nOn repart du code final de l’exercice 2.3, qui recodait une série de variables de hdv2003 en valeurs TRUE/FALSE dans de nouvelles variables avec le suffixe \"_true\".\n\ndetecte_oui &lt;- function(v) {\n    v == \"Oui\"\n}\nhdv2003 &lt;- hdv2003 %&gt;%\n    mutate(\n        across(\n            hard.rock:sport,\n            detecte_oui,\n            .names = \"{.col}_true\"\n        )\n    )\n\nCalculer le plus simplement possible une nouvelle variable total qui contient, pour chaque ligne, le nombre de valeurs TRUE des deux variables cinema_true et sport_true (si une ligne contient TRUE pour ces deux variables, total doit valoir 2, etc.)\n\n\nhdv2003 %&gt;%\n    mutate(total = cuisine_true + sport_true)\n\n\nRecalculer la variable total pour qu’elle contienne le nombre de TRUE par ligne pour les variables bricol_true, cinema_true et sport_true.\n\n\nhdv2003 %&gt;%\n    rowwise() %&gt;%\n    mutate(total = sum(cuisine_true, sport_true, bricol_true))\n\n\nRecalculer la variable total pour qu’elle contienne le nombre de TRUE par ligne pour toutes les variables se terminant par \"_true\".\n\n\nhdv2003 %&gt;%\n    rowwise() %&gt;%\n    mutate(total = sum(c_across(ends_with(\"_true\"))))\n\n\nReprendre le code précédent pour qu’il puisse s’appliquer directement sur les variables hard.rock…sport, sans passer par le recodage en TRUE/FALSE.\n\n\ncount_oui &lt;- function(v) {\n    sum(v == \"Oui\")\n}\n\nhdv2003 %&gt;%\n    rowwise() %&gt;%\n    mutate(\n        total = count_oui(c_across(hard.rock:sport))\n    )\n\n\nExercice 4.2\nDans le jeu de données starwars, la colonne films contient la liste des films dans lesquels apparaissent les différents personnages. Cette colonne a une forme un peu particulière puisqu’il s’agit d’une “colonne-liste” : les éléments de cette colonne sont eux-mêmes des listes.\n\nhead(starwars$films, 3)\n\nOn essaye de calculer le nombre de films pour chaque personnage avec le code suivant. Est-ce que ça fonctionne ? Pourquoi ?\n\nstarwars %&gt;%\n    mutate(n_films = length(films))\n\nTrouver une manière d’obtenir le résultat attendu.\n\n\nstarwars %&gt;%\n    rowwise() %&gt;%\n    mutate(n_films = length(films))",
    "crumbs": [
      "Calcul Numérique",
      "TP4 : Fonctions et manipulation de données"
    ]
  },
  {
    "objectID": "CMI-SIG-intro.html",
    "href": "CMI-SIG-intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Le cours en résumé :\n\n24 h\nobjectifs : appréhender les données géographiques et maîtriser les principales opérations sur ce type de données (intersection, distance etc)\nLangage : R & QGIS (introduction)\nmodalités d’examens:\n\nNote de participation\nUn projet commun SIG/économétrie avec choix du sujet imposé\nPrésentation en classe d’une carte réalisée avec QGIS : 3mn de présentation\n\n\nLe plan :\n\nIntroduction à QGIS\nTraitement sur les données vectorielles\nLes SIG avec R\n\nToutes les données des TP sont disponibles sur ce drive.",
    "crumbs": [
      "SIG",
      "Introduction"
    ]
  },
  {
    "objectID": "CMI-SIG-TP1.html",
    "href": "CMI-SIG-TP1.html",
    "title": "TP1 : Introduction à QGIS",
    "section": "",
    "text": "1. Prise en main",
    "crumbs": [
      "SIG",
      "TP1 : Introduction à QGIS"
    ]
  },
  {
    "objectID": "CMI-SIG-TP1.html#prise-en-main",
    "href": "CMI-SIG-TP1.html#prise-en-main",
    "title": "TP1 : Introduction à QGIS",
    "section": "",
    "text": "1.1 Affichage / désaffichage des panneaux\n\nFermez les panneaux Couches et Identifier les résultats.\n\nAffichez-les de nouveau avec le menu Vue &gt; Panneaux.\n\n\n\n1.2 Utilisation de données vecteur\nToutes les données des TP sont disponibles sur ce drive.\n\nExaminez la liste des fichiers du répertoire Data/ADMIN EXPRESS.\n\nAffichez :\n\nARRONDISSEMENT.shp\n\nEPCI.shp\n\ncommunes_ara.gpkg\n\n\nOuvrez la table attributaire de la couche ARRONDISSEMENT :\n\nTrier selon la colonne INSEE_DEP.\n\nQuels sont les arrondissements du département de la Loire (42) ?\n\n\nSupprimez la couche ARRONDISSEMENT.\n\nOuvrez les propriétés de la couche COMMUNE :\n\nNotez le système de coordonnées, la géométrie, la liste des attributs.\n\n\nOuvrez la table attributaire de la couche COMMUNE :\n\nQuel est le nombre de communes ?\n\n\nIdentifiez la commune de Saint-Maurice-en-Gourgois :\n\nDans quel département est-elle ?\n\nChargez la couche DEPARTEMENT.shp et identifiez le département 43.\n\nQuelle est sa population (champ POPULATION) ?\n\n\n\n\n1.3 Création d’un projet\n\nEnregistrez le projet sous le nom TP1-1.qgs.\n\n\n\n1.4 Utilisation de l’outil Identifier les entités\n\nUtilisez l’outil sur Saint-Maurice-en-Gourgois : quelle est la longueur du périmètre ?\n\nZoomez sur la dalle.\n\n\n\n1.5 Jointure 1\n\nJoindre la couche EPCI à COMMUNE.\n\nQuel est le nom de l’EPCI de Saint-Maurice-en-Gourgois ?\n\n\n\n1.6 Utilisation d’OpenStreetMap\n\nCréez une connexion XYZ :\n\n\n\nNom : OpenStreetMap\nURL : https://tile.openstreetmap.org/{z}/{x}/{y}.png\n\n\nInstallez l’extension QuickMapServices.\n\nAffichez le fond de carte OSM Standard.\n\n\n\n1.7 Ordre des couches et opacité\n\nClassez les couches dans l’ordre : Communes → EPCI → Arrondissement.\n\n\n\n1.8 Groupe de couches\n\nGroupez ARRONDISSEMENT et COMMUNE en ADMIN.\n\n\n\n1.9 Outil de mesure\n\nMesurez la distance maximale de Saint-Maurice-en-Gourgois.\n\n\n\n1.10 Sélection et export\n\nSélectionnez les communes d’Auvergne-Rhône-Alpes.\n\nExportez dans CommunesEPCI_ARA.gpkg.\n\nCréez une couche des seuls EPCI d’Auvergne-Rhône-Alpes.\n\n\n\n1.11 Sélection et conditions multiples\n\nCommunes ARA &gt; 1000 habitants → combien ?\n\nCommunes Haute-Loire &gt; 1000 habitants → combien ?\n\nExportez les deux sélections.",
    "crumbs": [
      "SIG",
      "TP1 : Introduction à QGIS"
    ]
  },
  {
    "objectID": "CMI-SIG-TP1.html#symbologie-1-pays-du-monde",
    "href": "CMI-SIG-TP1.html#symbologie-1-pays-du-monde",
    "title": "TP1 : Introduction à QGIS",
    "section": "2. Symbologie 1 : Pays du monde",
    "text": "2. Symbologie 1 : Pays du monde\n\nTéléchargez les données physiques et culturelles de NaturalEarth à 50m sur ce lien\nOuvrez :\n\n\n\nne_50m_admin_0_countries\n\nne_50m_populated_places_simple\n\nne_50m_geographic_lines\n\n\n\nAvec la première couche, créez une symbologie par PIB du pays (GDP_MD) en prenant une graduation Jenks.\n\nUtilisez palette Viridis, projection World Robinson (EPSG:54030).\n\nRenommez la couche : Countries by GDP.\n\nEnregistrez le projet : TP1_2.qgz.\n\n\n2.1 Mise en page\n\nCréez une mise en page gpd en A4 paysage.\n\nAjoutez carte, légende, fond gris clair, export en PNG 300 dpi.\n\n\n\n2.2 Rendu gradué : Villes du monde\n\nUtilisez pop_max.\n\nCréez 6 classes (Jenks ou seuils manuels).\n\nSymbole ponctuel rose, transparence 60 %, taille 0.5–4 mm.\n\nExportez en PNG 300 dpi.\n\n\n\n2.2 Symboles proportionnels\n\nSymbole unique, rose, transparence 60 %.\n\nTaille proportionnelle pop_max.\n\nEnregistrez le projet.",
    "crumbs": [
      "SIG",
      "TP1 : Introduction à QGIS"
    ]
  },
  {
    "objectID": "CMI-SIG-TP1.html#symbologie-2-france",
    "href": "CMI-SIG-TP1.html#symbologie-2-france",
    "title": "TP1 : Introduction à QGIS",
    "section": "3. Symbologie 2 : France",
    "text": "3. Symbologie 2 : France\nOuvrir :\n\nliste_cheflieu.geojson,\noccitanie_communes.gpkg,\noccitanue_limites.gpkg,\nliste-des-gares.geojson,\nRéseauFerré.gpkg\n\nDans cette parties, il faut faire une carte de l’occitanie en utilisant les 5 jeux de données\n\n3.1 Styles\n\nRégions en gris clair + bordures blanches.\n\nChefs-lieux : symboles catégorisés (Préfecture région et Préfecture).\n\nRéseau ferré : catégorisé sur type_voie.\n\nCommunes Occitanie : densité de population (Jenks, OrRd, bornes manuelles).\n\n\n\n3.2 Étiquettes\n\nChefs-lieux avec règles selon statut administratif.\n\n\n\n3.3 Mise en page finale\n\nA4 portrait, titre Réseau ferré en Occitanie, carte 1/2 000 000, légende, échelle, nord, sources.\n\nAjoutez une carte miniature France + Occitanie.\n\nExport PNG et PDF.",
    "crumbs": [
      "SIG",
      "TP1 : Introduction à QGIS"
    ]
  },
  {
    "objectID": "CMI-SIG-TP2.html",
    "href": "CMI-SIG-TP2.html",
    "title": "TP2 : Traitement sur les données vectorielles",
    "section": "",
    "text": "1. Données de départ\nDans un nouveau projet, ouvrez les couches :\n- departement_occitanie.gpkg\n- CLC12_RLRMP_RGF.shp\nPour visualiser les types d’occupation du sol avec les couleurs standard Corine Land Cover, ouvrez les propriétés de la couche et chargez le fichier de style CLC12.sld (dans le dossier FichiersLegende).\nAjoutez aussi :\n- trace-du-reseau-autoroutier-doccitanie.geojson\n- dreal-occitanie-mats-eoliens.geojson\nEnregistrez le projet sous le nom TP2.qgz.",
    "crumbs": [
      "SIG",
      "TP2 : Traitement sur les données vectorielles"
    ]
  },
  {
    "objectID": "CMI-SIG-TP2.html#création-dun-geopackage",
    "href": "CMI-SIG-TP2.html#création-dun-geopackage",
    "title": "TP2 : Traitement sur les données vectorielles",
    "section": "2. Création d’un GeoPackage",
    "text": "2. Création d’un GeoPackage\nToutes les couches produites seront enregistrées dans une base unique GeoPackage.\n\nCréez TP2_couches.gpkg (répertoire data) en exportant la couche des mâts éoliens.\n\nOptions :\n\nformat = GeoPackage\nnom fichier = TP2_couches.gpkg\nnom couche = Mâts éoliens\nSCR = EPSG:2154",
    "crumbs": [
      "SIG",
      "TP2 : Traitement sur les données vectorielles"
    ]
  },
  {
    "objectID": "CMI-SIG-TP2.html#zone-tampon-sur-lautoroute-a61",
    "href": "CMI-SIG-TP2.html#zone-tampon-sur-lautoroute-a61",
    "title": "TP2 : Traitement sur les données vectorielles",
    "section": "3. Zone tampon sur l’autoroute A61",
    "text": "3. Zone tampon sur l’autoroute A61\n\n3.1 Vérification du SCR\nDans les propriétés de trace-du-reseau-autoroutier-doccitanie, identifiez le système de coordonnées.\n\n\n3.2 Conversion en Lambert 93\nExporte la couche vers TP2_couches.gpkg avec :\n- nom couche = Réseau autoroutier\n- SCR = EPSG:2154\n\n\n3.3 Sélection et tampon\n\nOuvrir la table attributaire → champ num_route.\n\nSélectionner les tronçons correspondant à A61.\n\nCréer un tampon de 5000 m avec options :\n\nentités sélectionnées uniquement = Oui\n\nNb segments = 10\n\nextrémités = Rond\n\nregrouper = Oui\n\nsortie = TP2_couches.gpkg → Tampon A61 5000m\n\n\n\n\n3.4 Analyse\nAvec Compter les points dans les polygones, combien d’éoliennes se trouvent dans cette zone tampon ?",
    "crumbs": [
      "SIG",
      "TP2 : Traitement sur les données vectorielles"
    ]
  },
  {
    "objectID": "CMI-SIG-TP2.html#matrice-de-distance",
    "href": "CMI-SIG-TP2.html#matrice-de-distance",
    "title": "TP2 : Traitement sur les données vectorielles",
    "section": "4. Matrice de distance",
    "text": "4. Matrice de distance\nPour chaque mât éolien, calculer la distance avec les 2 plus proches voisins.\n- entrée = Mâts éoliens\n- identifiant = id_mat\n- type = Matrice de distance linéaire (Nk+3)*\n- k = 2\n- sortie = TP2_couches.gpkg → Calcul Eoliennes 2 voisins\nInspectez le résultat avec l’outil Identifier : remarquez-vous le type de géométrie ?",
    "crumbs": [
      "SIG",
      "TP2 : Traitement sur les données vectorielles"
    ]
  },
  {
    "objectID": "CMI-SIG-TP2.html#grille-hexagonale",
    "href": "CMI-SIG-TP2.html#grille-hexagonale",
    "title": "TP2 : Traitement sur les données vectorielles",
    "section": "5. Grille hexagonale",
    "text": "5. Grille hexagonale\n\n5.1 Création\n\nDans departement_occitanie, sélectionnez l’Aude et zoomez.\n\nAvec Créer une grille :\n\ntype = hexagonale\n\nétendue = canevas\n\nespacement = 5000\n\nSCR = EPSG:2154\n\nsortie = TP2_couches.gpkg → Grille Aude 5km\n\n\n\n\n5.2 Nettoyage\nSupprimez les hexagones hors de l’Aude :\n- sélection par localisation → inverser → supprimer en mode édition.",
    "crumbs": [
      "SIG",
      "TP2 : Traitement sur les données vectorielles"
    ]
  },
  {
    "objectID": "CMI-SIG-TP2.html#comptages-dans-la-grille",
    "href": "CMI-SIG-TP2.html#comptages-dans-la-grille",
    "title": "TP2 : Traitement sur les données vectorielles",
    "section": "6. Comptages dans la grille",
    "text": "6. Comptages dans la grille\n\nCompter points/polygones → nb d’éoliennes par maille hexagonale.\n\nsortie = TP2_couches.gpkg → Calcul nb éoliennes\n\n\nSomme longueurs lignes → total autoroutes par maille.\n\nsortie = TP2_couches.gpkg → Calcul long autoroutes",
    "crumbs": [
      "SIG",
      "TP2 : Traitement sur les données vectorielles"
    ]
  },
  {
    "objectID": "CMI-SIG-TP2.html#analyse-de-superposition-corine-land-cover",
    "href": "CMI-SIG-TP2.html#analyse-de-superposition-corine-land-cover",
    "title": "TP2 : Traitement sur les données vectorielles",
    "section": "7. Analyse de superposition (Corine Land Cover)",
    "text": "7. Analyse de superposition (Corine Land Cover)\n\n7.1 Sélection des forêts\nSélectionner dans CLC12_RLRMP_RGF les polygones dont CODE_12 commence par “3”.\nExporter vers TP2_couches.gpkg → CLC12 Forets Milieux SemiNat.\n\n\n7.2 Superposition\nAvec Analyse de superposition :\n- source = Grille Aude 5km\n- superposition = CLC12 Forets Milieux SemiNat\n- sortie = TP2_couches.gpkg → Calcul P ForetsSemiNat",
    "crumbs": [
      "SIG",
      "TP2 : Traitement sur les données vectorielles"
    ]
  },
  {
    "objectID": "CMI-SIG-TP2.html#intersection-et-group-stats",
    "href": "CMI-SIG-TP2.html#intersection-et-group-stats",
    "title": "TP2 : Traitement sur les données vectorielles",
    "section": "8. Intersection et Group Stats",
    "text": "8. Intersection et Group Stats\n\n8.1 Zone tampon des parcs\nCréer tampon 2000 m autour de chaque mât → Tampon Eol 2000m.\nPuis regrouper par id_parc, n_parc → Calcul ParcEol 2000m.\n\n\n8.2 Intersection avec CLC\nAvec Intersection :\n- source = CLC12_RLRMP_RGF\n- superposition = Tampon Eol 2000m\n- champs conservés : ID, CODE_12, id_parc, n_parc\n- sortie = TP2_couches.gpkg → Calcul Inter ParcEol CLC12\n\n\n8.3 Tableau croisé dynamique\nDans l’extension Group Stats :\n- Couches = Calcul Inter ParcEol CLC12\n- Colonnes = CODE_12\n- Lignes = id_parc, n_parc\n- Valeurs = Surface (somme)\nExporter le tableau et coller dans Excel/Calc.",
    "crumbs": [
      "SIG",
      "TP2 : Traitement sur les données vectorielles"
    ]
  },
  {
    "objectID": "CMI-SIG-TP3.html",
    "href": "CMI-SIG-TP3.html",
    "title": "TP3 : SIG avec R",
    "section": "",
    "text": "1. Premières cartes\nChargez les libraries suivantes :",
    "crumbs": [
      "SIG",
      "TP3 : SIG avec R"
    ]
  },
  {
    "objectID": "CMI-SIG-TP3.html#premières-cartes",
    "href": "CMI-SIG-TP3.html#premières-cartes",
    "title": "TP3 : SIG avec R",
    "section": "",
    "text": "Décrire l’objet Utilisez world. Utiliser summary() sur la colonne de géométrie de l’objet world inclus dans le package spData. Utilisez ggplot2. Tracez la carte des continents. Utiliser le theme_void(). Tracez le continent asiatique, en filtrant puis appliquant la fonction d’union de formes géométrique st_union.\n\n\nRajouter à la carte des continents des ronds pour chaque pays représentant la racine carré de leur population divisé par 10000. Il faudra pour ça calculer les centroides de chaque pays avec la commande st_centroid du package sf\n\n\nTracez la carte de l’Inde dans le continent asiatique. Il faut :\n\n\nfiltrer et tracer le continent asiatique dans world .\ncréer un object india qui filtre l’Inde dans world .\nrajouter la carte le l’Inde en grisant son contour\ncréer le centroide de l’inde et rajouter sur la carte une étiquette “Inde” à la coordonnée du centroide du pays\n\n\nCréer un raster de 10x10 pixels avec la commande rast, dont les niveaux avec des valeurs aléatoires allant de 0 à 10 (avec la commande runif). Tracez ce raster avec geom_raster.\n\n\nChargez le fichier raster/nlcd.tif du package spDataLarge à l’aide de la commande. Décrire cet objet. Utiliser la fonction plot. Enfin, convertir le raster en objet du package stars et décrire le résultat.",
    "crumbs": [
      "SIG",
      "TP3 : SIG avec R"
    ]
  },
  {
    "objectID": "CMI-SIG-TP3.html#opérations-sur-les-attributs",
    "href": "CMI-SIG-TP3.html#opérations-sur-les-attributs",
    "title": "TP3 : SIG avec R",
    "section": "2. Opérations sur les attributs",
    "text": "2. Opérations sur les attributs\nPour ces exercices, nous utiliserons les ensembles de données us_states et us_states_df du package spData.\n\nCréez un nouvel objet appelé us_states_name qui contient uniquement la colonne NAME de l’objet us_states en utilisant la syntaxe de base R ([) ou tidyverse (select()). Quelle est la classe du nouvel objet et qu’est-ce qui le rend géographique?\n\n\nSélectionnez les colonnes de l’objet us_states contenant les données de population. Obtenez le même résultat en utilisant une autre commande (bonus : essayez de trouver trois façons d’obtenir le même résultat). Indice : essayez d’utiliser des fonctions d’aide, telles que contains ou matches de dplyr (voir ?contains).\n\n\nTrouvez tous les États ayant les caractéristiques suivantes (bonus : trouvez-les et affichez-les) :\n\n\nAppartiennent à la région Midwest.\nAppartiennent à la région Ouest, ont une superficie inférieure à 250 000 km2 et en 2015, une population supérieure à 5 000 000 d’habitants (astuce : vous devrez peut-être utiliser la fonction units::set_units() ou as.numeric()).\nAppartiennent à la région Sud, avaient une superficie supérieure à 150 000 km2 ou une population totale en 2015 supérieure à 7 000 000 d’habitants.\n\n\nQuelle était la population totale en 2015 dans l’ensemble de données us_states ? Quelle était la population minimale et maximale en 2015 ?\n\n\nCombien d’États y a-t-il dans chaque région ?\nQuelle était la population minimale et maximale en 2015 dans chaque région ? Quelle était la population totale en 2015 dans chaque région ?\nAjoutez des variables de us_states_df à us_states et créez un nouvel objet appelé us_states_stats. Quelle fonction avez-vous utilisée et pourquoi ? Quelle variable sert de clé dans les deux ensembles de données ? Quelle est la classe du nouvel objet ?\nus_states_df a deux lignes de plus que us_states. Comment pouvez-vous les trouver ? (astuce : essayez d’utiliser la fonction dplyr::anti_join())\nQuelle était la densité de population en 2015 dans chaque État ? Quelle était la densité de population en 2010 dans chaque État ?\nCombien la densité de population a-t-elle changé entre 2010 et 2015 dans chaque État ? Calculez le changement en pourcentage et cartographiez-le.\nChangez les noms des colonnes dans us_states en minuscules. (Astuce : les fonctions d’aide - tolower() et colnames() peuvent aider.)\nUtilisez us_states et us_states_df pour créer un nouvel objet appelé us_states_sel. Le nouvel objet ne doit contenir que deux variables - median_income_15 et geometry. Changez le nom de la colonne median_income_15 en Income.\nCalculez le changement du nombre de résidents vivant en dessous du seuil de pauvreté entre 2010 et 2015 pour chaque État. (Astuce : voir ?us_states_df pour la documentation sur les colonnes du seuil de pauvreté.) Bonus : Calculez le changement en pourcentage des résidents vivant en dessous du seuil de pauvreté dans chaque État.\nQuelle était la population minimale, moyenne et maximale des personnes vivant en dessous du seuil de pauvreté en 2015 pour chaque région ? Bonus : Quelle est la région où l’augmentation du nombre de personnes vivant en dessous du seuil de pauvreté est la plus importante ?\n\n\nCréez un raster grain vide avec neuf lignes et colonnes et une résolution de 0,5 degré décimal (WGS84). Remplissez-le avec des nombres aléatoires. Extraire les valeurs des quatre cellules de coin.\nQuelle est la classe la plus courante de notre exemple de raster grain ?\nTracez l’histogramme et la boîte à moustaches du fichier dem.tif du package spDataLarge (system.file(\"raster/dem.tif\", package = \"spDataLarge\")).",
    "crumbs": [
      "SIG",
      "TP3 : SIG avec R"
    ]
  },
  {
    "objectID": "CMI-SIG-TP3.html#opération-sur-les-données-spatiales",
    "href": "CMI-SIG-TP3.html#opération-sur-les-données-spatiales",
    "title": "TP3 : SIG avec R",
    "section": "3. Opération sur les données spatiales",
    "text": "3. Opération sur les données spatiales\n\n3.1 Opérations sur les vecteurs\n\nUtiliser les jeux de données nz et nz_height du package spData. Combien de ces points élevés la région de Canterbury contient-elle ?\n\nBonus : tracez le résultat en utilisant la fonction plot() pour montrer toute la Nouvelle-Zélande, la région de Canterbury en jaune, les points élevés à Canterbury représentés par des croix rouges (astuce : pch = 7) et les points élevés dans d’autres parties de la Nouvelle-Zélande représentés par des cercles bleus. Consultez la page d’aide ?points pour plus de détails avec une illustration des différentes valeurs pch.\n\nQuelle région a le deuxième plus grand nombre de points nz_height, et combien en a-t-elle ?\nEn généralisant la question à toutes les régions : combien des 16 régions de Nouvelle-Zélande contiennent des points qui appartiennent aux 100 points les plus élevés du pays ? Quelles sont ces régions ?\n\nBonus : créez un tableau listant ces régions par ordre du nombre de points et leur nom.\n\nLe point de départ de cet exercice est de créer un objet représentant l’État du Colorado aux États-Unis. Faites ceci avec la fonction filter() (tidyverse) et tracez l’objet résultant dans le contexte des États-Unis.\n\n\nCréez un nouvel objet représentant tous les États qui se chevauchent géographiquement avec le Colorado et tracez le résultat (astuce : la manière la plus concise de le faire est avec la méthode de sous-ensemble [).\nCréez un autre objet représentant tous les objets qui touchent (ont une frontière commune avec) le Colorado et tracez le résultat (astuce : souvenez-vous que vous pouvez utiliser l’argument op = st_intersects et d’autres relations spatiales lors des opérations de sous-ensemble spatial en R de base).\n\nBonus : créez une ligne droite allant du centroïde du district de Columbia près de la côte Est au centroïde de la Californie près de la côte Ouest des États-Unis (astuce : les fonctions st_centroid(), st_union() et st_cast() peuvent aider) et identifiez quels États cette longue ligne est.",
    "crumbs": [
      "SIG",
      "TP3 : SIG avec R"
    ]
  },
  {
    "objectID": "CMI-SIG-TP3.html#opérations-sur-les-rasters",
    "href": "CMI-SIG-TP3.html#opérations-sur-les-rasters",
    "title": "TP3 : SIG avec R",
    "section": "3.2 Opérations sur les rasters",
    "text": "3.2 Opérations sur les rasters\n\nUtilisez dem = rast(system.file(\"raster/dem.tif\", package = \"spDataLarge\")), et reclassifiez l’élévation en trois classes : basse (&lt;300), moyenne et haute (&gt;500). Ensuite, lisez le raster NDVI (ndvi = rast(system.file(\"raster/ndvi.tif\", package = \"spDataLarge\"))) et calculez la moyenne du NDVI et de l’élévation pour chaque classe d’altitude.\nAppliquez un filtre de détection de lignes à rast(system.file(\"ex/logo.tif\", package = \"terra\")). Tracez le résultat. Astuce : Lisez ?terra::focal().\n\n7 Calculez l’indice d’eau normalisé (NDWI ; (green - nir)/(green + nir)) d’une image Landsat. Utilisez l’image Landsat fournie par le package spDataLarge (system.file(\"raster/landsat.tif\", package = \"spDataLarge\")). Calculez également une corrélation entre le NDVI et le NDWI pour cette région (astuce : vous pouvez utiliser la fonction layerCor()).\n\nUn message sur StackOverflow montre comment calculer les distances jusqu’à la côte la plus proche en utilisant raster::distance(). Essayez de faire quelque chose de similaire mais avec terra::distance(): récupérez un modèle numérique d’élévation de l’Espagne et calculez un raster qui représente les distances jusqu’à la côte à travers le pays (astuce : utilisez geodata::elevation_30s()). Convertissez les distances résultantes de mètres en kilomètres. Note : il peut être judicieux d’augmenter la taille de cellule du raster d’entrée pour réduire le temps de calcul lors de cette opération (aggregate()).\nEssayez de modifier l’approche utilisée dans l’exercice ci-dessus en pondérant le raster de distance avec le raster d’élévation ; chaque tranche de 100 mètres d’altitude devrait augmenter la distance jusqu’à la côte de 10 km. Ensuite, calculez et visualisez la différence entre le raster créé en utilisant la distance euclidienne (E7) et le raster pondéré par l’élévation.",
    "crumbs": [
      "SIG",
      "TP3 : SIG avec R"
    ]
  },
  {
    "objectID": "CMI-SIG-TP3.html#opérations-sur-les-géométries",
    "href": "CMI-SIG-TP3.html#opérations-sur-les-géométries",
    "title": "TP3 : SIG avec R",
    "section": "4. Opérations sur les géométries",
    "text": "4. Opérations sur les géométries\n\n4.1 Opérations sur les vecteurs\n\nGénérez et tracez des versions simplifiées de l’ensemble de données nz. Expérimentez avec différentes valeurs de keep (allant de 0,5 à 0,00005) pour ms_simplify() et dTolerance (de 100 à 100 000) pour st_simplify().\n\n\nÀ partir de quelle valeur le résultat commence-t-il à se détériorer pour chaque méthode, rendant la Nouvelle-Zélande méconnaissable ?\nAvancé : Quelle est la différence entre le type de géométrie des résultats de st_simplify() par rapport au type de géométrie de ms_simplify() ? Quels problèmes cela crée-t-il et comment cela peut-il être résolu ?\n\n\nDans le premier exercice du chapitre sur les opérations de données spatiales, il a été établi que la région de Canterbury avait 70 des 101 points les plus élevés de Nouvelle-Zélande. En utilisant st_buffer(), combien de points dans nz_height se trouvent à moins de 100 km de Canterbury ?\nTrouvez le centroïde géographique de la Nouvelle-Zélande. À quelle distance se trouve-t-il du centroïde géographique de Canterbury ?\nLa plupart des cartes du monde ont une orientation nord en haut. Une carte du monde avec une orientation sud en haut pourrait être créée par une réflexion (l’une des transformations affines non mentionnées dans ce chapitre) de la géométrie de l’objet world. Écrivez le code pour le faire. Astuce : vous devez utiliser un vecteur à deux éléments pour cette transformation. Bonus : créez une carte à l’envers de votre pays.\nCalculez la longueur des lignes de frontières des États-Unis en mètres. Quel État a la frontière la plus longue et lequel a la frontière la plus courte ? Astuce : La fonction st_length calcule la longueur d’une géométrie de type LINESTRING ou MULTILINESTRING. Il faut aussi transformer la géométrieavec un CRS qui puisse calculer des ditances : ici ESPG=2163.\nExécutez le code de la section 5.2.6. En référence aux objets créés dans cette section, sélectionnez le point dans p qui est contenu à la fois dans x et y.\n\n\nUtilisez les opérateurs de sous-ensemble de base.\nUtilisez un objet intermédiaire créé avec st_intersection().\n\n\nExécutez le code suivant :\n\n\nbb = st_bbox(st_union(x, y))\nbox = st_as_sfc(bb)\nset.seed(2024)\np = st_sample(x = box, size = 10)\np_xy1 = p[x_and_y]\nplot(box, border = \"gray\", lty = 2)\nplot(x, add = TRUE, border = \"gray\")\nplot(y, add = TRUE, border = \"gray\")\nplot(p, add = TRUE, cex = 3.5)\nplot(p_xy1, cex = 5, col = \"red\", add = TRUE)\ntext(x = c(-0.5, 1.5), y = 1, labels = c(\"x\", \"y\"), cex = 3)\n\nEn référence aux objets créés dans cette section, sélectionnez le point dans p qui est contenu à la fois dans x et y.\n\nUtilisez les opérateurs de sous-ensemble de base.\nUtilisez un objet intermédiaire créé avec st_intersection().\n\n\n\n4.2 Opérations sur les rasters\n\nLisez le fichier srtm.tif dans R (srtm = rast(system.file(\"raster/srtm.tif\", package = \"spDataLarge\"))). Ce raster a une résolution de 0,00083 par 0,00083 degrés. Modifiez sa résolution en 0,01 par 0,01 degrés en utilisant toutes les méthodes disponibles dans le package terra. Visualisez les résultats. Pouvez-vous remarquer des différences entre les résultats de ces méthodes de rééchantillonnage ?",
    "crumbs": [
      "SIG",
      "TP3 : SIG avec R"
    ]
  },
  {
    "objectID": "CMI-SIG-TP3.html#application-rapprochement-de-base-par-distances",
    "href": "CMI-SIG-TP3.html#application-rapprochement-de-base-par-distances",
    "title": "TP3 : SIG avec R",
    "section": "5. Application : rapprochement de base par distances",
    "text": "5. Application : rapprochement de base par distances\nLe but de cet exercice est d’identifier la nature de stations de services. Un jeu de données issu de https://www.data.gouv.fr/fr/datasets/prix-des-carburants-en-france-flux-instantane-v2-amelioree/ donne les prix des carburants mais on n’a pas d’information sur le type de station (station d’autoroute, de supermarché…). Le jeu de données magasins d’openstreetmap pourrait permettre d’apporter des informations.\n\nCharger les données de TP3.zip. Les gpkg s’ouvrent la commande st_read du package sf.\nRestreindre la base magasins aux types de magasins (shop) suivants : “gas”,“supermarket”,“convenience”, “car_repair”,“car”,“mall”,“convenience;gas”\nTransformer les deux jeux en sf dataframe en système de coordonnées EPSG 2154. Attention, pour la base station, il faut diviser longitude et latitude par 100000.\nPour chaque station station, le magasins le plus proche et calculer la distance correspondate.\nQuelle est la part des magasins à moins de 100 mètres d’une station.\nAjouter les attributs shop et operator pour chaque magasins les plus proche à la base stations.",
    "crumbs": [
      "SIG",
      "TP3 : SIG avec R"
    ]
  },
  {
    "objectID": "CMI-E1-intro.html",
    "href": "CMI-E1-intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Le cours en résumé : - 30 h - objectifs : développer, interpréter et critiquer des modèles économétriques - modalités d’examens: - Note de participation - Un projet commun calcul numérique/économétrie avec choix du sujet libre - Un projet commun SIG/économétrie avec choix du sujet imposé\nLe plan : 1. Statistiques et probabilités en R 2. Régression linéaire multiple 3. Projet 1 4. Projet 2",
    "crumbs": [
      "Econométrie 1",
      "Introduction"
    ]
  },
  {
    "objectID": "CMI-E1-TP1.html",
    "href": "CMI-E1-TP1.html",
    "title": "TP1 : Probabilités et Statistiques avec R",
    "section": "",
    "text": "1. Probabilités avec R",
    "crumbs": [
      "Econométrie 1",
      "TP1 : Probabilités et Statistiques avec R"
    ]
  },
  {
    "objectID": "CMI-E1-TP1.html#probabilités-avec-r",
    "href": "CMI-E1-TP1.html#probabilités-avec-r",
    "title": "TP1 : Probabilités et Statistiques avec R",
    "section": "",
    "text": "1.1 - Échantillonnage\nVous êtes la fée des loteries dans une loterie hebdomadaire, où 6 numéros uniques sur 49 sont tirés.\n\nTirez aléatoirement les numéros gagnants de cette semaine (fixez la graine à 123) en utilisant la fonction sample.\n\n\n\n1.2 - Fonction de densité de probabilité\nConsidérez une variable aléatoire \\(X\\) avec une fonction de densité de probabilité (PDF)\n\\[f_X(x)=\\frac{x}{4}e^{-x^2/8},\\quad x\\geq 0.\\]\n\nDéfinissez la PDF ci-dessus comme une fonction \\(f()\\).\nVérifiez si la fonction que vous avez définie est effectivement une PDF (indice : utilisez la fonction integrate).\n\n\n\n1.3 - Espérance et Variance\nDans cet exercice, vous devez calculer l’espérance et la variance de la variable aléatoire \\(X\\) considérée dans l’exercice précédent.\nLa PDF \\(f()\\) de l’exercice précédent est disponible dans votre environnement de travail.\n\nDéfinissez une fonction appropriée ex() qui s’intègre à l’espérance de \\(X\\).\nCalculez l’espérance de \\(X\\). Stockez le résultat dans expected_value.\nDéfinissez une fonction appropriée ex2() qui s’intègre à l’espérance de \\(X^2\\).\nCalculez la variance de \\(X\\). Stockez le résultat dans variance.\n\n\n\n1.4 - Distribution Normale Standard\nSoit \\(Z \\sim \\mathcal{N}(0, 1)\\) .\n\nCalculez \\(\\phi(3)\\), c’est-à-dire la valeur de la densité de probabilité standard normale en \\(3\\).\nCalculez $ P(|Z| ) $ en utilisant la fonction pnorm().\n\nIndications : en R contient des distributions de probabilités pré-enregistrées (norm pour la distribution normale, chiqsq pour chi2, t pour Student). La syntaxe est la suivante :\n\nd → densité (ex: dnorm)\np → probabilité (ex: pnorm). Pour cette fonction, on utilise souvent l’option lower.tail=F pour calculer la probabilité complémentaire.\nq → quantile (ex: qnorm)\nr → tirage aléatoire (ex: rnorm)\n\n\n\n1.5 - Distribution du Chi-carré\n\nSoit \\(W\\sim \\chi^2_{1,0}\\). Tracez la PDF correspondante à l’aide de curve(). Spécifiez la plage de valeurs \\(x\\) comme [0,25] via l’argument xlim.\nSoient \\(X_1\\) et \\(X_2\\) deux variables aléatoires normalement distribuées indépendantes avec \\(\\mu=0\\) et \\(\\sigma^2=15\\). Calculez \\(P(X_1^2+X_2^2&gt;10)\\)\n\n\n\n1.6 - Distribution de Student\n\nSoit \\(X\\sim t_{10000}\\) et \\(Z \\sim N(0,1)\\). Calculez le quantile à 95 % des deux distributions. Que remarquez-vous ?\nSoit \\(X\\sim t_1\\). Générez 1000 nombres aléatoires à partir de cette distribution et attribuez-les à la variable x. Calculez la moyenne de l’échantillon de x. Pouvez-vous expliquer le résultat ?\n\n\n\n1.7 - Distribution de Fisher\n\nSoit \\(Y \\sim F(10,4)\\). Tracez la fonction quantile de la distribution donnée à l’aide de la fonction curve().\nSoit \\(Y \\sim F(4,5)\\). Calculez \\(P(1&lt;Y&lt;10)\\) en intégrant la PDF avec la fonction integrate.",
    "crumbs": [
      "Econométrie 1",
      "TP1 : Probabilités et Statistiques avec R"
    ]
  },
  {
    "objectID": "CMI-E1-TP1.html#statistiques-avec-r",
    "href": "CMI-E1-TP1.html#statistiques-avec-r",
    "title": "TP1 : Probabilités et Statistiques avec R",
    "section": "2. Statistiques avec R",
    "text": "2. Statistiques avec R\n\n2.1 - Biais\nOn considère l’estimateur alternatif suivant pour \\(\\mu_Y\\), la moyenne de \\(Y\\) : \\[\\widetilde{Y}= \\frac{1}{n-1}\\sum_{i=1}^n Y_i\\]\n\nDéfinissez une fonction Y_tilde() qui implémente l’estimateur ci-dessus.\nTirez aléatoirement 5 observations au hasard à partir de la distribution \\(N(10,25)\\) et calculez une estimation en utilisant Y_tilde(). Répétez cette procédure 10000 fois et stockez les résultats dans est_biased en utilisant la fonction replicate.\nTracez un histogramme de est_biased. Ajoutez une ligne verticale rouge à \\(\\mu=10\\) en utilisant la fonction abline().\nTirez aléatoirement 1000 observations au hasard à partir de la distribution \\(N(10,25)\\) et calculez une estimation de la moyenne en utilisantY_tilde(). Répétez cette procédure 10000 fois et stockez les résultats dans est_consistent.\nTracez un histogramme de est_consistent. Ajoutez une ligne verticale rouge à \\(\\mu=10\\) en utilisant la fonction abline().\n\n\n\n2.2 - Efficience d’un estimateur\nDans cet exercice, nous souhaitons illustrer le résultat selon lequel la moyenne de l’échantillon :\n\\[\\widehat{\\mu}_Y=\\sum\\limits_{i=1}^{n} a_i Y_i\\] avec le schéma de pondération égale \\(a_i=\\frac{1}{n}\\) pour \\(i=1,...,n\\) est l’estimateur linéaire non biaisé meilleur (BLUE) de \\(\\mu_Y\\).\nEn tant qu’alternative, considérez l’estimateur :\n\\[\\widetilde{\\mu}_Y=\\sum\\limits_{i=1}^{n}b_iY_i\\]\noù \\(b_i\\) donne aux premières \\(\\frac{n}{2}\\) observations un poids plus élevé de 3 que les deuxièmes \\(\\frac{n}{2}\\) observations (nous supposons que \\(n\\) est pair pour simplifier).\n%Le vecteur de poids \\(w\\) a déjà été défini et est disponible dans votre environnement de travail.\n\nDéfinissez un vecteur de pondération pour une taille d’échantillon n=100. Il doit être normalisé.\nVérifiez que \\(\\tilde{\\mu}_Y\\) est un estimateur non biaisé de \\(\\mu_Y\\), la moyenne de \\(Y_i\\).\nImplémentez l’estimateur alternatif de \\(\\mu_Y\\) en tant que fonction mu_tilde().\nTirez au hasard 100 observations à partir de la distribution \\(\\mathcal{N}(5, 10)\\) et calculez les estimations avec les deux estimateurs. Répétez cette procédure 10000 fois et stockez les résultats dans est_bar et est_tilde. Utilisez la fonction replicate.\nCalculez les variances de l’échantillon de est_bar et est_tilde. Que pouvez-vous dire sur les deux estimateurs?\n\n\n\n2.3 - Test d’hypothèse\nConsidérez l’ensemble de données wage1 du package wooldridge. La variable wage donne les gains horaires moyens des individus. Nous supposons que les gains horaires moyens wage dépassent 10 dollars par heure et souhaitons tester cette hypothèse à un niveau de signification de \\(\\alpha=0,05\\). Veuillez faire ce qui suit :\n\nCalculez la statistique de test manuellement et attribuez-la à tstat.\nUtilisez tstat pour accepter ou rejeter l’hypothèse nulle.\nRefaites-le en utilisant l’approximation normale.\nCalculez la valeur-p manuellement et attribuez-la à pval en utilisant l’approximation normale.\nUtilisez pval pour accepter ou rejeter l’hypothèse nulle.\nEffectuez le test d’hypothèse des questions précédentes en utilisant la fonction t.test().\nExtrayez la statistique t et la valeur-p de la liste créée par t.test(). Attribuez-les aux variables tstat et pvalue.\nVérifiez que l’utilisation de l’approximation normale ici est également valide en calculant la différence entre les deux valeurs-p.\n\n\n\n2.4 - Test d’hypothèse : valeur-p\nOn considère les données CO2 (data(CO2)).\n\nTester s’il existe une différence significative dans l’absorption entre les plantes traitées et les plantes non traitées à un niveau de signification de \\(\\alpha\\)=0,05.\nObtenez l’intervalle de confiance.\n\n\n\n2.5 - Corrélation\nCharger la librairie corrgram et le jeu de données auto.\n\nCalculez la corrélation simple (linéaire) entre le prix de la voiture (Price) et son économie de carburant MPG (mesurée en miles par gallon, ou mpg).\nUtilisez la fonction cor.test pour vérifier si le coefficient obtenu est statistiquement significatif au niveau de 5 %.\nLa corrélation simple suppose une relation linéaire entre les variables, mais il peut être utile de relâcher cette hypothèse. Calculez le coefficient de corrélation de Spearman pour les mêmes variables et trouvez sa signification statistique.\nEn R, il est possible de calculer la corrélation pour toutes les paires de variables numériques dans un dataframe en une seule fois. Cependant, cela nécessite d’exclure d’abord les variables non numériques. Créez un nouveau dataframe, auto_num, qui ne contient que les colonnes avec des valeurs numériques du dataframe auto. Vous pouvez le faire en utilisant la fonction filter.\nUtilisez la fonction cor pour créer une matrice de coefficients de corrélation pour les variables du dataframe auto_num.\nLa fonction standard cor.test ne fonctionne pas avec des dataframes. Cependant, la signification statistique des coefficients de corrélation pour un dataframe peut être vérifiée à l’aide de la fonction rcorr du package Hmisc. Transformez le dataframe auto_num en une matrice (auto_mat) et utilisez-le pour vérifier la signification des coefficients de corrélation avec la fonction rcorr.\nUtilisez la fonction corrgram du package corrgram pour créer un correlogramme par défaut afin de visualiser les corrélations entre les variables du dataframe auto.\nCréez un autre correlogramme qui (1) ne comprend que le panneau inférieur, (2) utilise des diagrammes en camembert pour représenter les coefficients de corrélation et (3) ordonne les variables selon l’ordre par défaut.\nCréez un nouveau dataframe, auto_subset, en sous-échantillonnant le dataframe auto pour inclure uniquement les variables Price, MPG, Hroom et Rseat. Utilisez le nouveau dataframe pour créer un correlogramme qui (1) affiche les coefficients de corrélation dans le panneau inférieur et (2) montre des diagrammes de dispersion (points) dans le panneau supérieur.\nUtilisez la fonction correlations du package ggm pour créer une matrice de corrélation avec à la fois des coefficients de corrélation complets et partiels pour le dataframe auto_subset. Trouvez la corrélation partielle entre le prix de la voiture et son économie de carburant.",
    "crumbs": [
      "Econométrie 1",
      "TP1 : Probabilités et Statistiques avec R"
    ]
  },
  {
    "objectID": "CMI-E1-TP2.html",
    "href": "CMI-E1-TP2.html",
    "title": "TP 2 : Modèle de régression multiple",
    "section": "",
    "text": "Introduction\nLancez et ouvrez un nouveau . Ce sera votre document de travail durant tout le TP. L’intérêt des Markdown est de pouvoir lancer une multitude de petits scripts successivement. Typiquement, un (petit script) par question. Lorsque c’est nécessaire, répondez aux questions entre les chunks.\nCréez un fichier partagé “Econométrie-votre nom” sur votre drive fourni de l’université (OneDrive ou Google Drive). Envoyez-moi le lien de ce drive. Ce dossier partagé sera votre dossier de travail pendant toute la durée du cours. Créez un dossier “TP1” et enregistrez-y votre markdown sous le nom “TP1”.",
    "crumbs": [
      "Econométrie 1",
      "TP 2 : Modèle de régression multiple"
    ]
  },
  {
    "objectID": "CMI-E1-TP2.html#bwght",
    "href": "CMI-E1-TP2.html#bwght",
    "title": "TP 2 : Modèle de régression multiple",
    "section": "bwght",
    "text": "bwght\n\nUn problème qui intéresse les responsables de santé (et d’autres) est de déterminer les effets du tabagisme pendant la grossesse sur la santé des nourrissons. L’une des mesures de la santé du nourrisson est le poids de naissance ; un poids de naissance trop faible peut exposer le nourrisson au risque de contracter diverses maladies. Étant donné que des facteurs autres que le tabagisme qui influent sur le poids à la naissance sont susceptibles d’être corrélés au tabagisme, nous devons tenir compte de ces facteurs. Par exemple, un revenu plus élevé donne généralement accès à de meilleurs soins prénataux, ainsi qu’à une meilleure nutrition pour la mère. Une équation qui en tient compte est la suivante :\n\\[ bwght = \\beta_0 + \\beta_1 cigs +\\beta_2 faminc + u \\]\nAvec \\(bwght\\) le poids du bébé à la naissance, \\(cigs\\) le nombre de cigarette fumées par jour par la mère, et \\(faminc\\) le revenu de la famille.\n\nQuel est le signe le plus probable pour \\(\\beta_2\\) ?\nPensez-vous que \\(cigs\\) et \\(faminc\\) sont susceptibles d’être corrélés ? Expliquez pourquoi cette corrélation corrélation pourrait être positive ou négative.\nMaintenant, estimez l’équation avec et sans \\(faminc\\)\n\nPrésentez les résultats sous forme d’équation, y compris la taille de l’échantillon et le \\(R^2\\). Discutez de vos résultats, en vous concentrant sur la question de savoir si l’ajout de la \\(faminc\\) modifie sensiblement l’effet estimé de la cigarette sur le poids corporel.",
    "crumbs": [
      "Econométrie 1",
      "TP 2 : Modèle de régression multiple"
    ]
  },
  {
    "objectID": "CMI-E1-TP2.html#hprice1",
    "href": "CMI-E1-TP2.html#hprice1",
    "title": "TP 2 : Modèle de régression multiple",
    "section": "hprice1",
    "text": "hprice1\nUtilisez les données pour estimer le modèle :\n\\[ price = \\beta_0 + \\beta_1 sqrft + \\beta_2 bdrms + u\\]\noù \\(price\\) est le prix de la maison mesuré en milliers de dollars, \\(sqrft\\) est la surface du logement et \\(bdrms\\) le nombre de chambres.\n\nRédigez les résultats sous forme d’équation.\nQuelle est l’augmentation estimée du prix d’une maison comportant une chambre à coucher de plus, la superficie en pieds carrés étant constante ?\nQuelle est l’augmentation estimée du prix d’une maison avec une chambre supplémentaire de 140 pieds carrés ? Comparez ce résultat à votre réponse dans la partie (ii).\nQuel pourcentage de la variation du prix s’explique par la superficie en pieds carrés et le nombre de chambres à coucher ?\nLa première maison de l’échantillon a une superficie de $sqrft = $2438$ et un nombre de chambres à coucher \\(bdrms = 4\\)$. Trouvez le prix de vente prédit pour cette maison à partir de la ligne de régression MCO.\nLe prix de vente réel de la première maison de l’échantillon est de 300 000 $ (donc \\(price\\) = 300). Trouvez le résidu pour cette maison. Cela suggère-t-il que l’acheteur a sous-payé ou sur-payé la maison ?",
    "crumbs": [
      "Econométrie 1",
      "TP 2 : Modèle de régression multiple"
    ]
  },
  {
    "objectID": "CMI-E1-TP2.html#ceosal2",
    "href": "CMI-E1-TP2.html#ceosal2",
    "title": "TP 2 : Modèle de régression multiple",
    "section": "ceosal2",
    "text": "ceosal2\nLe fichier contient des données sur 177 PDG et peut être utilisé pour examiner les effets de la performance de l’entreprise sur le salaire du PDG.\n\nEstimez un modèle reliant le salaire annuel \\(salary\\) aux ventes de l’entreprise \\(sales\\) et à la valeur marchande \\(mktval\\). Transformer le modèle de façon à obtenir des élasticités constantes pour les deux variables indépendantes. Écrivez les résultats sous forme d’équation.\nAjoutez \\(profits\\) au modèle de la partie (i). Pourquoi cette variable ne peut-elle pas être incluse sous sous forme logarithmique ? Diriez-vous que ces variables de performance de l’entreprise expliquent la plus grande partie de la variation des salaires des PDG ?\nAjoutez la variable \\(ceoten\\) au modèle de la partie (ii). Quel est le pourcentage de rendement estimé estimé pour une année supplémentaire de mandat du PDG, les autres facteurs étant fixes ?\nTrouvez le coefficient de corrélation de l’échantillon entre les variables \\(\\log(mktval)\\) et \\(profits\\). Ces variables sont-elles fortement corrélées ? Qu’est-ce que cela signifie pour les estimateurs MCO ?",
    "crumbs": [
      "Econométrie 1",
      "TP 2 : Modèle de régression multiple"
    ]
  },
  {
    "objectID": "CMI-E1-TP2.html#attend",
    "href": "CMI-E1-TP2.html#attend",
    "title": "TP 2 : Modèle de régression multiple",
    "section": "attend",
    "text": "attend\nCet exercice étudie les lien entre entre présence en classe et réussite scolaire. Utilisez les données de pour cet exercice.\n\nObtenez les valeurs minimum, maximum et moyenne pour les variables \\(atndrte\\) (pourcentage de présence en classe), \\(priGPA\\) (GPA cumulé), et \\(ACT\\) (score ACT).\nEstimez le modèle \\[atndrte = \\beta_0 + \\beta_1 priGPA + \\beta_2 ACT + u\\] et écrivez les résultats sous forme d’équation. Interprétez l’ordonnée à l’origine. A-t-il une signification utile ?\nDiscutez les coefficients de pente estimés. Y a-t-il des surprises ?\nQuel est \\(atndrte\\) prédit si \\(priGPA\\) = 3.65 et \\(ACT\\) = 20 ? Que pensez-vous de ce résultat ? Existe-t-il des étudiants dans l’échantillon avec ces valeurs des variables explicatives ?\nSi l’étudiant A a une \\(priGPA\\) de 3,1 et un \\(ACT\\) de 21, et que l’étudiant B a une \\(priGPA\\) de 2,1 et un \\(ACT\\) de 26, quelle est la valeur de \\(atndrte\\) ? et \\(ACT  = 26\\), quelle est la différence prédite dans leurs taux de présence ?",
    "crumbs": [
      "Econométrie 1",
      "TP 2 : Modèle de régression multiple"
    ]
  },
  {
    "objectID": "CMI-E1-TP2.html#meap93",
    "href": "CMI-E1-TP2.html#meap93",
    "title": "TP 2 : Modèle de régression multiple",
    "section": "meap93",
    "text": "meap93\nUtilisez les données de pour répondre à cette question.\n\nEstimez le modèle \\[math_{10} = \\beta_0 + \\beta_1 \\log(expend) + \\beta_2 lnchprg + u\\]\n\net rapportez les résultats sous la forme habituelle, y compris la taille de l’échantillon et le R-carré. Les signes des coefficients de pente sont-ils ceux que vous attendiez ? Expliquez. (ii) Que faites-vous de l’ordonnée à l’origine que vous avez estimée dans la partie (i) ? En particulier, cela a-t-il un sens de mettre les deux variables explicatives à zéro ? (Indice : rappelez-vous que \\(\\log(1)=0\\)). (iii) Exécutez maintenant la régression simple de math10 sur \\(\\log(expend)\\), et comparez le coefficient de pente avec l’estimation obtenue dans la partie (i). L’effet de dépense estimé est-il maintenant plus grand ou plus petit que dans la partie (i) ? (iv) Trouvez la corrélation entre \\(lexpend = \\log(expend)\\) et \\(lnchprg\\). Son signe vous semble-t-il logique ? (v) Utilisez la partie (iv) pour expliquer vos résultats dans la partie (iii).",
    "crumbs": [
      "Econométrie 1",
      "TP 2 : Modèle de régression multiple"
    ]
  },
  {
    "objectID": "CMI-E1-TP2.html#discrim",
    "href": "CMI-E1-TP2.html#discrim",
    "title": "TP 2 : Modèle de régression multiple",
    "section": "discrim",
    "text": "discrim\nUtilisez les données de pour répondre à cette question. Il s’agit de données au niveau du code postal sur les prix de divers articles dans les fast-foods, ainsi que des caractéristiques de la population du code postal, dans le New Jersey et en Pennsylvanie. L’idée est de voir si les restaurants fast-food pratiquent des prix plus élevés dans les zones où la concentration de Noirs est plus importante. (i) Trouvez les valeurs moyennes de \\(prpblck\\) et de revenu dans l’échantillon, ainsi que leurs écarts types. Quelles sont les unités de mesure de \\(prpblck\\) et du revenu ? (ii) Considérez un modèle pour expliquer le prix du soda, \\(psoda\\), en fonction de la proportion de la population qui est noire et du revenu médian :\n\\[ psoda = \\beta_0 + \\beta_1 prpblck + \\beta_2 revenu + u\\]\nEstimez ce modèle par MCO et rapportez les résultats sous forme d’équation, y compris la taille de l’échantillon et le R-carré. (N’utilisez pas la notation scientifique pour présenter les estimations.) Interprétez le coefficient de \\(prpblck\\). Pensez-vous qu’il soit économiquement important ?\n\nComparez l’estimation de la partie (ii) avec l’estimation de régression simple de \\(psoda\\) sur \\(prpblck\\). L’effet de discrimination est-il plus important ou plus faible lorsque vous contrôlez le revenu ?\nUn modèle avec une élasticité-prix constante par rapport au revenu pourrait être plus approprié. Présentez les estimations du modèle :\n\n\\[log(psoda) = \\beta_0 + \\beta_1 prpblck + \\beta_2log(income) + u \\]\nSi \\(prpblck\\) augmente de 0,20 (20 points de pourcentage), quelle est la variation estimée en pourcentage de \\(psoda\\) ? (Indice : la réponse est 2.xx, où vous remplissez le “xx”). (v) Ajoutez maintenant la variable \\(prppov\\) à la régression de la partie (iv). Que se passe-t-il ? attendu ?\n\nÉvaluez l’énoncé suivant : “Parce que le \\(log(income)\\) et la variable \\(prppov\\) sont si fortement corrélés, ils n’ont rien à faire dans la même régression.”",
    "crumbs": [
      "Econométrie 1",
      "TP 2 : Modèle de régression multiple"
    ]
  },
  {
    "objectID": "CMI-E1-TP2.html#charity",
    "href": "CMI-E1-TP2.html#charity",
    "title": "TP 2 : Modèle de régression multiple",
    "section": "charity",
    "text": "charity\nUtilisez les données de pour répondre aux questions suivantes :\n\nEstimez l’équation : \\[ gift = \\beta_0 + \\beta_1 mailsyear + \\beta_2 giftlast + \\beta_3 propresp + u \\] par MCO et rapportez les résultats de la manière habituelle, y compris la taille de l’échantillon et le R-carré. Comment le \\(R^2\\) se compare-t-il à celui de la régression simple qui omet \\(giftlast\\) et \\(propresp\\) ?\nInterprétez le coefficient de l’année postale. Est-il plus grand ou plus petit que le coefficient de régression simple correspondant ?\nInterprétez le coefficient de \\(propresp\\), en prenant soin de noter les unités de mesure de \\(propresp\\).\nAjoutez maintenant la variable \\(avggift\\) à l’équation. Que devient l’effet estimé de \\(mailsyear\\) ?\nDans l’équation de la partie (iv), qu’est-il arrivé au coefficient de \\(giftlast\\) ? A votre avis, que se passe-t-il ?",
    "crumbs": [
      "Econométrie 1",
      "TP 2 : Modèle de régression multiple"
    ]
  },
  {
    "objectID": "CMI-E1-TP2.html#htv",
    "href": "CMI-E1-TP2.html#htv",
    "title": "TP 2 : Modèle de régression multiple",
    "section": "htv",
    "text": "htv\nUtilisez les données de pour répondre à cette question. L’ensemble de données comprend des informations sur les salaires, l’éducation, l’éducation des parents et plusieurs autres variables pour 1 230 hommes actifs en 1991.\n\nQuelle est la fourchette de la variable éducation dans l’échantillon ? Quel pourcentage d’hommes ont terminé leur 12ème année mais pas une année supérieure ? Les hommes ou leurs parents ont-ils, en les hommes ou leurs parents ont-ils, en moyenne, un niveau d’éducation plus élevé ?\nEstimez le modèle de régression\n\n\\[ educ = \\beta_0 + \\beta_1 motheduc + \\beta_2 fatheduc + u \\] par MCO et présentez les résultats sous la forme habituelle. Quelle est la part de la variation de l’échantillon dans \\(educ\\) est expliquée par l’éducation des parents ? Interprétez le coefficient de \\(motheduc\\).\n\nAjoutez la variable \\(abil\\) (une mesure de l’aptitude cognitive) à la régression de la partie (ii), et rapportez les résultats.\nAjoutez la variable \\(abil\\) (une mesure de l’aptitude cognitive) à la régression de la partie (ii), et présentez les résultats sous forme d’équation. La “capacité” permet-elle d’expliquer expliquer les variations de l’éducation, même après avoir contrôlé l’éducation des parents ? Expliquez.\n(Nécessite un calcul) Estimez maintenant une équation où l’aptitude apparaît sous forme quadratique :\n\n\\[  educ = \\beta_0 + \\beta_1 motheduc + \\beta_2 fatheduc + \\beta_3 abil + \\beta_4 abil^2 + u \\]\nEn utilisant les estimations \\(\\hat{\\beta}_3\\) et \\(\\hat{b}_4\\), utiliser le calcul pour trouver la valeur de \\(abil\\), l’appeler \\(abil^\\star\\) , où \\(educ\\) est minimisé. (Les autres coefficients et valeurs des variables d’éducation des parents n’ont pas d’effet ; nous maintenons l’éducation des parents fixe). Remarquez que \\(abil\\) est mesuré de manière à ce que des valeurs négatives soient autorisées. Vous pouvez également vérifier que la dérivée seconde est positive et que vous avez bien un minimum.\n\nArgumentez que seule une petite fraction des hommes de l’échantillon a une “capacité” inférieure à la valeur calculée dans la partie (iv). En quoi cela est-il important ?\n\n\n\nSi vous avez accès à un programme statistique qui comprend des capacités graphiques, utilisez les estimations de la partie (iv) pour représenter graphiquement la relation entre l’éducation et l’aptitude prédites. Supposons que la \\(motheduc\\) et la \\(fatheduc\\) ont leurs valeurs moyennes dans l’échantillon, 12.18 et 12.45, respectivement.",
    "crumbs": [
      "Econométrie 1",
      "TP 2 : Modèle de régression multiple"
    ]
  },
  {
    "objectID": "CMI-E1-TP3.html",
    "href": "CMI-E1-TP3.html",
    "title": "TP3 : Analyse des Disparités Scolaires au Collège",
    "section": "",
    "text": "0. Installation.\nLes inégalités de performance scolaire sont un sujet récurrent dans les débats sur le système éducatif. Parmi les examens importants en France, le brevet des collèges permet de mesurer les compétences acquises par les élèves à la fin du cycle secondaire. Cependant, les résultats obtenus peuvent varier en fonction de divers facteurs, notamment le contexte socio-économique local.\nCe TP vous propose d’explorer l’influence de facteurs socio-économiques, tels que le revenu médian, le taux de chômage ou encore le niveau d’éducation dans les communes, sur les résultats du brevet des collèges. À travers l’analyse de jeux de données réels, vous serez amenés à identifier des corrélations et à mieux comprendre les déterminants de la performance scolaire.\nCharger les packages tidyverse, stargazer. ChatGPT ou autre chatbot sont autorisés pour ce TP.\nLes données socio-économiques sont bien formatées ici : https://www.unehistoireduconflitpolitique.fr/telecharger.html. Commencer par télécharger les données sur les revenus des communes. On pourra réitérer l’analyse sur les diplômes et les catégories socio-professionnelles.",
    "crumbs": [
      "Econométrie 1",
      "TP3 : Analyse des Disparités Scolaires au Collège"
    ]
  },
  {
    "objectID": "CMI-E1-TP3.html#installation.",
    "href": "CMI-E1-TP3.html#installation.",
    "title": "TP3 : Analyse des Disparités Scolaires au Collège",
    "section": "",
    "text": "Chercher sur internet et télécharger les données sur les résultats de brevets par établissement.",
    "crumbs": [
      "Econométrie 1",
      "TP3 : Analyse des Disparités Scolaires au Collège"
    ]
  },
  {
    "objectID": "CMI-E1-TP3.html#données-brevet",
    "href": "CMI-E1-TP3.html#données-brevet",
    "title": "TP3 : Analyse des Disparités Scolaires au Collège",
    "section": "1. Données Brevet",
    "text": "1. Données Brevet\n\n1.1 Description des données\n\nDécrire le jeu de données : colonnes, taille, niveau géographique, horizon temporel…\nQuelle est la période étudiée ?\nCombien y a-t-il d’établissements ?\n\n\n\n1.2 Evolution temporelle\nOn veut caractériser les résultas du brevet au niveau national.\n\nCréer un fichier de donnée aggrégé par année au niveau national (utiliser group_by et summarize).\nComment semble calculé la colonne taux_de_reussite. Tester son intuition une colonne taux_de_reussite2 et comparer avec taux_de_reussite.\nFaire des graphiques montrant l’évolution des nombres d’inscrits et d’admis.\nFaire des graphiques montrant le taux annuel d’admis.\nFaire des graphiques montrant les taux annuels d’admis pour chaque mention.\nDécrire et interpréter chaque graphiques.\n\n\n\n1.3 Variation en coupe\nOn considère la dernière session reportée par le jeu de donnée.\n\nCréer un jeu de donnée filtré sur cette dernière année.\nMontrer es graphiques en barres pour représenter les différences sur les taux de réussites selon le type d’établissement et le secteur d’enseignement.\nFaire des classements des dix meilleurs départements selon les différents taux de réussites.",
    "crumbs": [
      "Econométrie 1",
      "TP3 : Analyse des Disparités Scolaires au Collège"
    ]
  },
  {
    "objectID": "CMI-E1-TP3.html#données-socio-économiques",
    "href": "CMI-E1-TP3.html#données-socio-économiques",
    "title": "TP3 : Analyse des Disparités Scolaires au Collège",
    "section": "2. Données socio-économiques",
    "text": "2. Données socio-économiques\n\n2.1 Description du jeu de données\n\nDécrire le jeu de données de la même façon que pour le premier jeu. Utiliser les annexes où les données sont décrites.\nQuelles colonnes (ou ensemble de colonnes) vous semble-t-il pertinent de garder ?\n\n\n\n2.2 Transformation du jeu\nTransformer ce jeu de données en format “long” avec pivot_longer.",
    "crumbs": [
      "Econométrie 1",
      "TP3 : Analyse des Disparités Scolaires au Collège"
    ]
  },
  {
    "objectID": "CMI-E1-TP3.html#analyse-jointe-.",
    "href": "CMI-E1-TP3.html#analyse-jointe-.",
    "title": "TP3 : Analyse des Disparités Scolaires au Collège",
    "section": "3. Analyse jointe .",
    "text": "3. Analyse jointe .\n\n3.1 Jointure\nPour chaque année et pour chaque établissement, on souhaite avoir les informations socio-économiques de la commune correspondante.\n\nFaire la jointure entre les deux jeux de données.\nAnalyser les données manquantes du nouveau jeu de données.\n\n\n\n3.2 Analyse en coupe\n\nFaire des graphiques par points représentant le revenu moyen de la commune de l’établissement avec ses différents taux de réussites.\nFaire des graphiques en bar dans lequel par décile de revenu (utiliser la colonne de percentile coté socioeco).\n\n\n\n3.3 Regressions linéaire\nPour une année donnée vs toutes taux de reussite en fonction de la taille de la commune, revenus moyen\n\nFaites une régression\n\nNotes: - on fait les régressions avec la commande lm. - Pour visualiser les régressions, on enregistre les résultats de chaque regressions (eg, lm1,lm2…) et on visualise avec la commande stargazer du package du même nom (eg stargazer(type=\"text\",lm1,lm2)).",
    "crumbs": [
      "Econométrie 1",
      "TP3 : Analyse des Disparités Scolaires au Collège"
    ]
  },
  {
    "objectID": "CMI-E1-TP4.html",
    "href": "CMI-E1-TP4.html",
    "title": "TP4 : Etude économétrique de l’Enquête Nationale Transport 2019",
    "section": "",
    "text": "1. Enoncé\nDans ce TP, nous allons travaillons sur enquête nationale de l’INSEE. Vous aurez la liberté de choisir une question de recherche et de sélectionner les variables qui vous semblent pertinentes (en n’en prenant pas trop tout de même).\nLes données sont disponibles ici : sur le site du ministère.\nOn considère les caractéristiques socio-économiques des ménages suivantes : le revenu, la catégorie socio-professionnelle, le lieux de résidence, la composition du ménage (nombre de personnes, age).\nQuestions : comment varie les grandeurs suivantes en fonction des grandeurs suivantes:\nTravail à faire :",
    "crumbs": [
      "Econométrie 1",
      "TP4 : Etude économétrique de l'Enquête Nationale Transport 2019"
    ]
  },
  {
    "objectID": "CMI-E1-TP4.html#enoncé",
    "href": "CMI-E1-TP4.html#enoncé",
    "title": "TP4 : Etude économétrique de l’Enquête Nationale Transport 2019",
    "section": "",
    "text": "les caractéristiques du véhicule : age, motorisation\ndistance et nombre de trajets parcourue à velo pour les trajets du quotidient\ndistance et nombre de trajets parcourue en voiture en commun pour les trajets du quotidient\ndistance et nombre de trajets parcourue en transport en commun pour les trajets du quotidient\ndistance et nombre de trajets parcourue en avion pour les voyages\n\n\n\nidentifier dans les jeux de données où trouver les informations pertinentes\neffectuer des statistiques descriptives sur les caractéristiques socio-économiques\nconstruire votre jeu de donnée en construisant les grandeurs de transport puis en réalisant en appariemment sur les données socioéconomiques.\nEffectuer des régressions linéaires en combinant différemment les variables de controlms.",
    "crumbs": [
      "Econométrie 1",
      "TP4 : Etude économétrique de l'Enquête Nationale Transport 2019"
    ]
  },
  {
    "objectID": "CMI-E2-intro.html",
    "href": "CMI-E2-intro.html",
    "title": "Introduction",
    "section": "",
    "text": "24 h\nobjectifs : économétrie avancée : tests statistiques (en parallèle du cours) et introduction à l’inférence causale\nmodalités d’examens :\n\nNote de participation (10%)\nPrésentations en groupe en classe de chapitre du manuel d’inférence causale de Scott Cunningham (40%)\nProjet 3 d’économétrie (50%)\nS’incrire ici pour les projets et présentations : fichier Excel partagé.\n\n\nLe plan : 1. Régression linéaire multiple et tests 2. Binaires et effets fixes 4. Multicolinéarité 5. Hétéroskédasticité 6. Panels\nPrésentation: Dans l’atelier Econométrie 1, nous nous sommes introduit aux concepts élémentaires de l’économétries : régressions linéaires multiples, estimation, significativité. Cet atelier vise à étendre votre connaissance des modèles linéaires sur les cas où les hypothèses de bases ne sont pas respectées (multicolinéarité, hétéroskédasticité etc). En parallèle, il cherche à vous introduire à l’approche de l’inférence causale, qui est le concept empirique dominant en économie et sciences sociales aujourd’hui. Pour ce faire, nous allons faire une lecture collective de l’ouvrage de Scott Cunningham, Causal Inference: the Mixtape. Dans le projet, nous reprendrons le projet 2 et chercherons à appliquer une des méthodes les plus classiques : les différences en différences.",
    "crumbs": [
      "Econométrie 2",
      "Introduction"
    ]
  },
  {
    "objectID": "CMI-E2-TP1.html",
    "href": "CMI-E2-TP1.html",
    "title": "1  TP 1 : Modèle de régression multiple",
    "section": "",
    "text": "1.1 Introduction\nLancez et ouvrez un nouveau . Ce sera votre document de travail durant tout le TP. L’intérêt des Markdown est de pouvoir lancer une multitude de petits scripts successivement. Typiquement, un (petit script) par question. Lorsque c’est nécessaire, répondez aux questions entre les chunks.\nCréez un fichier partagé “Econométrie-votre nom” sur votre drive fourni de l’université (OneDrive ou Google Drive). Envoyez-moi le lien de ce drive. Ce dossier partagé sera votre dossier de travail pendant toute la durée du cours. Créez un dossier “TP1” et enregistrez-y votre markdown sous le nom “TP1”.",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>TP 1 : Modèle de régression multiple</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP1.html#rappel-sur-r",
    "href": "CMI-E2-TP1.html#rappel-sur-r",
    "title": "1  TP 1 : Modèle de régression multiple",
    "section": "1.2 Rappel sur R",
    "text": "1.2 Rappel sur R\n\nChargez le package (téléchargez-le si besoin). Ouvrez le fichier de données \\(CASchools\\) avec la commande : data(CASchools).\nDéfinissez les variables \\(STR = students/teachers\\) et \\(score = (read + math)/2\\).\nAffichez les statistiques descriptives de ce jeu de données avec la commande .\nEstimez le modèle suivant avec la commande et affichez les résultats de la régression :\n\n\\[ score = \\beta_0 + \\beta_1 STR +\\beta_2 english + u \\]\n\nReprérentez els résultats précédents à l’air du et utilisez la commande stargazer( \\(data\\) , type = ‘text’) en remplaçant \\(data\\) par les jeux de données précédemment appelés.\n\n\n\nFaites la même chose avec la fonction feols() du package fixest pour lm et etable() pour stargazer.",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>TP 1 : Modèle de régression multiple</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP1.html#retour-sur-la-régression-multiple",
    "href": "CMI-E2-TP1.html#retour-sur-la-régression-multiple",
    "title": "1  TP 1 : Modèle de régression multiple",
    "section": "1.3 Retour sur la régression multiple",
    "text": "1.3 Retour sur la régression multiple\nLa première partie de ce TP vise à reproduire manuellement les fonctions de régression basiques de R. On considère le modèle linéaire suivant :\n\\[ Y = X'\\beta + u\\]\nLe but de cet exercice est de reproduire les résultats de la fonction \\(lm\\) de R tels qu’obtenus à la partie précédente.\n\nRappelez la formule générale de l’estimateur des moindres carrés ordinaires (MCO) \\(\\hat{\\beta}\\) sous forme matricielle.\nProposez une fonction sur R qui prennent en argument un vecteur \\(Y\\) et une matrice \\(X\\) de variables dépendantes et renvoie l’estimateur \\(\\hat{\\beta}\\) . Appliquez votre fonction de façon à reproduire les résultats de la regression précédentes.\nRappelez la formule de l’estimateur des moindres carrés ordinaires (MCO) \\(\\hat{\\sigma}^2\\) de la variance des résidus et la matrice de variance-covariance associée aux coefficients.\nModifiez la fonction de la question (ii) pour y intégrer l’estimateur des MCO de la déviation standard des résidus, et l’erreur standard \\(\\hat{\\sigma}_{\\beta_i}\\) associé à chaque coefficient \\(\\beta_i\\). Combinez \\(\\hat{\\beta}\\) et les \\(\\hat{\\sigma}_{\\beta_i}\\) dans un dataframe avec comme nom de colonnes “coefficient” et “déviation standard”. Appliquez votre fonction de façon à reproduire les résultats de la régression précédentes.\nRappelez la formule du \\(R^2\\). Modifiez votre fonction pour que le dataframe intègre aussi le \\(R^2\\). Appliquez votre fonction de façon à reproduire les résultats de la régression précédentes.\nRappelez les formules des statistiques de Fisher \\(F\\) et de student \\(t_i\\) pour chaque coefficient.\nModifier la fonction pour y ajouter les tests sur le coefficient. Le résultat de votre fonction reverra un dataframe avec des dans des colonnes séparées :\nAppliquez votre fonction de façon à reproduire les résultats de la régression précédentes.",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>TP 1 : Modèle de régression multiple</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP1.html#exercices",
    "href": "CMI-E2-TP1.html#exercices",
    "title": "1  TP 1 : Modèle de régression multiple",
    "section": "1.4 Exercices",
    "text": "1.4 Exercices\nCes exercices utilisent les données issus du package wooldridge.\n\n1.4.1 bwght\n\nUn problème qui intéresse les responsables de santé (et d’autres) est de déterminer les effets du tabagisme pendant la grossesse sur la santé des nourrissons. L’une des mesures de la santé du nourrisson est le poids de naissance ; un poids de naissance trop faible peut exposer le nourrisson au risque de contracter diverses maladies. Étant donné que des facteurs autres que le tabagisme qui influent sur le poids à la naissance sont susceptibles d’être corrélés au tabagisme, nous devons tenir compte de ces facteurs. Par exemple, un revenu plus élevé donne généralement accès à de meilleurs soins prénataux, ainsi qu’à une meilleure nutrition pour la mère. Une équation qui en tient compte est la suivante :\n\\[ bwght = \\beta_0 + \\beta_1 cigs +\\beta_2 faminc + u \\]\nAvec \\(bwght\\) le poids du bébé à la naissance, \\(cigs\\) le nombre de cigarette fumées par jour par la mère, et \\(faminc\\) le revenu de la famille.\n\nQuel est le signe le plus probable pour \\(\\beta_2\\) ?\nPensez-vous que \\(cigs\\) et \\(faminc\\) sont susceptibles d’être corrélés ? Expliquez pourquoi cette corrélation corrélation pourrait être positive ou négative.\nMaintenant, estimez l’équation avec et sans \\(faminc\\)\n\nPrésentez les résultats sous forme d’équation, y compris la taille de l’échantillon et le \\(R^2\\). Discutez de vos résultats, en vous concentrant sur la question de savoir si l’ajout de la \\(faminc\\) modifie sensiblement l’effet estimé de la cigarette sur le poids corporel.\n\n\n1.4.2 hprice1\nUtilisez les données pour estimer le modèle :\n\\[ price = \\beta_0 + \\beta_1 sqrft + \\beta_2 bdrms + u\\]\noù \\(price\\) est le prix de la maison mesuré en milliers de dollars, \\(sqrft\\) est la surface du logement et \\(bdrms\\) le nombre de chambres.\n\nRédigez les résultats sous forme d’équation.\nQuelle est l’augmentation estimée du prix d’une maison comportant une chambre à coucher de plus, la superficie en pieds carrés étant constante ?\nQuelle est l’augmentation estimée du prix d’une maison avec une chambre supplémentaire de 140 pieds carrés ? Comparez ce résultat à votre réponse dans la partie (ii).\nQuel pourcentage de la variation du prix s’explique par la superficie en pieds carrés et le nombre de chambres à coucher ?\nLa première maison de l’échantillon a une superficie de $sqrft = $2438$ et un nombre de chambres à coucher \\(bdrms = 4\\)$. Trouvez le prix de vente prédit pour cette maison à partir de la ligne de régression MCO.\nLe prix de vente réel de la première maison de l’échantillon est de 300 000 $ (donc \\(price\\) = 300). Trouvez le résidu pour cette maison. Cela suggère-t-il que l’acheteur a sous-payé ou sur-payé la maison ?\n\n\n\n1.4.3 ceosal2\nLe fichier contient des données sur 177 PDG et peut être utilisé pour examiner les effets de la performance de l’entreprise sur le salaire du PDG.\n\nEstimez un modèle reliant le salaire annuel \\(salary\\) aux ventes de l’entreprise \\(sales\\) et à la valeur marchande \\(mktval\\). Transformer le modèle de façon à obtenir des élasticités constantes pour les deux variables indépendantes. Écrivez les résultats sous forme d’équation.\nAjoutez \\(profits\\) au modèle de la partie (i). Pourquoi cette variable ne peut-elle pas être incluse sous sous forme logarithmique ? Diriez-vous que ces variables de performance de l’entreprise expliquent la plus grande partie de la variation des salaires des PDG ?\nAjoutez la variable \\(ceoten\\) au modèle de la partie (ii). Quel est le pourcentage de rendement estimé estimé pour une année supplémentaire de mandat du PDG, les autres facteurs étant fixes ?\nTrouvez le coefficient de corrélation de l’échantillon entre les variables \\(\\log(mktval)\\) et \\(profits\\). Ces variables sont-elles fortement corrélées ? Qu’est-ce que cela signifie pour les estimateurs MCO ?\n\n\n\n1.4.4 attend\nCet exercice étudie les lien entre entre présence en classe et réussite scolaire. Utilisez les données de pour cet exercice.\n\nObtenez les valeurs minimum, maximum et moyenne pour les variables \\(atndrte\\) (pourcentage de présence en classe), \\(priGPA\\) (GPA cumulé), et \\(ACT\\) (score ACT).\nEstimez le modèle \\[atndrte = \\beta_0 + \\beta_1 priGPA + \\beta_2 ACT + u\\] et écrivez les résultats sous forme d’équation. Interprétez l’ordonnée à l’origine. A-t-il une signification utile ?\nDiscutez les coefficients de pente estimés. Y a-t-il des surprises ?\nQuel est \\(atndrte\\) prédit si \\(priGPA\\) = 3.65 et \\(ACT\\) = 20 ? Que pensez-vous de ce résultat ? Existe-t-il des étudiants dans l’échantillon avec ces valeurs des variables explicatives ?\nSi l’étudiant A a une \\(priGPA\\) de 3,1 et un \\(ACT\\) de 21, et que l’étudiant B a une \\(priGPA\\) de 2,1 et un \\(ACT\\) de 26, quelle est la valeur de \\(atndrte\\) ? et \\(ACT  = 26\\), quelle est la différence prédite dans leurs taux de présence ?\n\n\n\n1.4.5 meap93\nUtilisez les données de pour répondre à cette question.\n\nEstimez le modèle \\[math_{10} = \\beta_0 + \\beta_1 \\log(expend) + \\beta_2 lnchprg + u\\]\n\net rapportez les résultats sous la forme habituelle, y compris la taille de l’échantillon et le R-carré. Les signes des coefficients de pente sont-ils ceux que vous attendiez ? Expliquez. (ii) Que faites-vous de l’ordonnée à l’origine que vous avez estimée dans la partie (i) ? En particulier, cela a-t-il un sens de mettre les deux variables explicatives à zéro ? (Indice : rappelez-vous que \\(\\log(1)=0\\)). (iii) Exécutez maintenant la régression simple de math10 sur \\(\\log(expend)\\), et comparez le coefficient de pente avec l’estimation obtenue dans la partie (i). L’effet de dépense estimé est-il maintenant plus grand ou plus petit que dans la partie (i) ? (iv) Trouvez la corrélation entre \\(lexpend = \\log(expend)\\) et \\(lnchprg\\). Son signe vous semble-t-il logique ? (v) Utilisez la partie (iv) pour expliquer vos résultats dans la partie (iii).\n\n\n1.4.6 discrim\nUtilisez les données de pour répondre à cette question. Il s’agit de données au niveau du code postal sur les prix de divers articles dans les fast-foods, ainsi que des caractéristiques de la population du code postal, dans le New Jersey et en Pennsylvanie. L’idée est de voir si les restaurants fast-food pratiquent des prix plus élevés dans les zones où la concentration de Noirs est plus importante. (i) Trouvez les valeurs moyennes de \\(prpblck\\) et de revenu dans l’échantillon, ainsi que leurs écarts types. Quelles sont les unités de mesure de \\(prpblck\\) et du revenu ? (ii) Considérez un modèle pour expliquer le prix du soda, \\(psoda\\), en fonction de la proportion de la population qui est noire et du revenu médian :\n\\[ psoda = \\beta_0 + \\beta_1 prpblck + \\beta_2 revenu + u\\]\nEstimez ce modèle par MCO et rapportez les résultats sous forme d’équation, y compris la taille de l’échantillon et le R-carré. (N’utilisez pas la notation scientifique pour présenter les estimations.) Interprétez le coefficient de \\(prpblck\\). Pensez-vous qu’il soit économiquement important ?\n\nComparez l’estimation de la partie (ii) avec l’estimation de régression simple de \\(psoda\\) sur \\(prpblck\\). L’effet de discrimination est-il plus important ou plus faible lorsque vous contrôlez le revenu ?\nUn modèle avec une élasticité-prix constante par rapport au revenu pourrait être plus approprié. Présentez les estimations du modèle :\n\n\\[log(psoda) = \\beta_0 + \\beta_1 prpblck + \\beta_2log(income) + u \\]\nSi \\(prpblck\\) augmente de 0,20 (20 points de pourcentage), quelle est la variation estimée en pourcentage de \\(psoda\\) ? (Indice : la réponse est 2.xx, où vous remplissez le “xx”). (v) Ajoutez maintenant la variable \\(prppov\\) à la régression de la partie (iv). Que se passe-t-il ? attendu ?\n\nÉvaluez l’énoncé suivant : “Parce que le \\(log(income)\\) et la variable \\(prppov\\) sont si fortement corrélés, ils n’ont rien à faire dans la même régression.”\n\n\n\n1.4.7 charity\nUtilisez les données de pour répondre aux questions suivantes :\n\nEstimez l’équation : \\[ gift = \\beta_0 + \\beta_1 mailsyear + \\beta_2 giftlast + \\beta_3 propresp + u \\] par MCO et rapportez les résultats de la manière habituelle, y compris la taille de l’échantillon et le R-carré. Comment le \\(R^2\\) se compare-t-il à celui de la régression simple qui omet \\(giftlast\\) et \\(propresp\\) ?\nInterprétez le coefficient de l’année postale. Est-il plus grand ou plus petit que le coefficient de régression simple correspondant ?\nInterprétez le coefficient de \\(propresp\\), en prenant soin de noter les unités de mesure de \\(propresp\\).\nAjoutez maintenant la variable \\(avggift\\) à l’équation. Que devient l’effet estimé de \\(mailsyear\\) ?\nDans l’équation de la partie (iv), qu’est-il arrivé au coefficient de \\(giftlast\\) ? A votre avis, que se passe-t-il ?\n\n\n\n1.4.8 htv\nUtilisez les données de pour répondre à cette question. L’ensemble de données comprend des informations sur les salaires, l’éducation, l’éducation des parents et plusieurs autres variables pour 1 230 hommes actifs en 1991.\n\nQuelle est la fourchette de la variable éducation dans l’échantillon ? Quel pourcentage d’hommes ont terminé leur 12ème année mais pas une année supérieure ? Les hommes ou leurs parents ont-ils, en les hommes ou leurs parents ont-ils, en moyenne, un niveau d’éducation plus élevé ?\nEstimez le modèle de régression\n\n\\[ educ = \\beta_0 + \\beta_1 motheduc + \\beta_2 fatheduc + u \\] par MCO et présentez les résultats sous la forme habituelle. Quelle est la part de la variation de l’échantillon dans \\(educ\\) est expliquée par l’éducation des parents ? Interprétez le coefficient de \\(motheduc\\).\n\nAjoutez la variable \\(abil\\) (une mesure de l’aptitude cognitive) à la régression de la partie (ii), et rapportez les résultats.\nAjoutez la variable \\(abil\\) (une mesure de l’aptitude cognitive) à la régression de la partie (ii), et présentez les résultats sous forme d’équation. La “capacité” permet-elle d’expliquer expliquer les variations de l’éducation, même après avoir contrôlé l’éducation des parents ? Expliquez.\n(Nécessite un calcul) Estimez maintenant une équation où l’aptitude apparaît sous forme quadratique :\n\n\\[  educ = \\beta_0 + \\beta_1 motheduc + \\beta_2 fatheduc + \\beta_3 abil + \\beta_4 abil^2 + u \\]\nEn utilisant les estimations \\(\\hat{\\beta}_3\\) et \\(\\hat{b}_4\\), utiliser le calcul pour trouver la valeur de \\(abil\\), l’appeler \\(abil^\\star\\) , où \\(educ\\) est minimisé. (Les autres coefficients et valeurs des variables d’éducation des parents n’ont pas d’effet ; nous maintenons l’éducation des parents fixe). Remarquez que \\(abil\\) est mesuré de manière à ce que des valeurs négatives soient autorisées. Vous pouvez également vérifier que la dérivée seconde est positive et que vous avez bien un minimum.\n\nArgumentez que seule une petite fraction des hommes de l’échantillon a une “capacité” inférieure à la valeur calculée dans la partie (iv). En quoi cela est-il important ?\n\n\n\nSi vous avez accès à un programme statistique qui comprend des capacités graphiques, utilisez les estimations de la partie (iv) pour représenter graphiquement la relation entre l’éducation et l’aptitude prédites. Supposons que la \\(motheduc\\) et la \\(fatheduc\\) ont leurs valeurs moyennes dans l’échantillon, 12.18 et 12.45, respectivement.",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>TP 1 : Modèle de régression multiple</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP2.html",
    "href": "CMI-E2-TP2.html",
    "title": "2  TP 2 : Régression multiple et variables binaires",
    "section": "",
    "text": "2.1 Exercices",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>TP 2 : Régression multiple et variables binaires</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP2.html#exercices",
    "href": "CMI-E2-TP2.html#exercices",
    "title": "2  TP 2 : Régression multiple et variables binaires",
    "section": "",
    "text": "2.1.1 gpa1\n\nEstimez le modèle : \\[colGPA = PC + hsGPA + ACT\\].\nAjoutez les variables mothcoll et fathcoll et reportez les résultats d’estimation. Qu’observez-vous pour le coefficient de la variable relative à la possession d’un PC ? PC apparaît-il toujours statistiquement significatif ?\nTestez pour la significativité jointe des coefficients associés aux variables mothcoll et fathcoll issues de l’équation en (i) en mentionnant les p-valeurs.\nAjoutez hsGPA^2 au modèle décrit en (i), jugez-vous cette généralisation pertinente ?\n\n\n\n2.1.2 wage2\n\nEstimez le modèle suivant :\n\n\\[log(wage) = \\beta_0 + \\beta_1 educ + \\beta_2 exper + \\beta_3 tenure + \\beta_4 married + \\beta_5 black + \\beta_6 south + \\beta_7 urban + u\\]\net reportez les résultats. Quelle est la différence approximative de salaire mensuel entre les afro-américains et les non afro-américains, toutes choses égales par ailleurs ? Cette différence est-elle statistiquement significative ?\n\nAjoutez les variables \\(exper^2\\) et \\(tenure^2\\) à l’équation précédente et montrez que les coefficients associés ne sont pas conjointement statistiquement significatifs au seuil de 5 %.\nAmendez le modèle original pour permettre aux rendements de l’éducation de dépendre des origines ethniques et testez si effectivement les rendements de l’éducation en dépendent.\nÀ nouveau, partez du modèle de base et amendez le ensuite en autorisant les salaires à différer selon les groupes : mariés et africains américains, mariés et non africains américains, non mariés et africains américains, non mariés et non africains américains. Quelle est la différence de salaire estimée entre les mariés afro-américains et non afro-américains ?\n\n\n\n2.1.3 mlb1\nUn modèle permettant de caractériser les salaires des joueurs de la ligue majeure de baseball aux États-Unis est donné par :\n\\[log(salary) = \\beta_0 + \\beta_1 years + \\beta_2 gamesyr + \\beta_3 bavg + \\beta_4 hrunsyr +\\beta_5 rbisyr \\] \\[ + \\beta_6 runsyr + \\beta_7 fldperc + \\beta_8 allstar + \\beta_9 frstbase + \\beta_{10} scndbase \\] \\[ + beta_{11} thrdbase + \\beta_{12} shrtstop + \\beta_{13} catcher + u \\]\navec outfield (joueur de champ extérieur) le groupe de référence.\n\nÉtablissez formellement l’hypothèse nulle selon laquelle, toutes choses égales par ailleurs, attrapeurs (catcher) et joueurs de champ extérieur gagnent en moyenne le même revenu. Calculez le salaire moyen par groupe.\nTestez ensuite cette hypothèse à partir des données contenues dans la base mlb1 et commentez l’étendue du différentiel de salaire.\nÉtablissez formellement et testez l’hypothèse selon laquelle il n’y a aucune différence de salaire moyen selon les postes occupés, une fois l’ensemble des variables de contrôle prises en compte.\nLes résultats tirés des questions (i) et (ii) sont-ils cohérents ? Dans le cas contraire, expliquez le mécanisme sous-jacent.\n\n\n\n2.1.4 gpa2\n\nOn considère le modèle suivant : \\[colgpa=\\beta_0 +\\beta_1 hsize+\\beta_2 hsize^2 +\\beta_3 hsperc+\\beta_4 sat  + \\beta_5 female + \\beta_6 athlete + u, \\]\n\navec colgpa la moyenne des notes obtenues en premier cycle à l’université, hsize la taille de la classe au lycée, en centaines, hsperc le quantile dans lequel se situe l’étudiant à l’issue de son parcours universitaire, sat le score SAT, female une variable binaire relative au genre, et athlete une variable binaire prenant la valeur un si l’étudiant est un athlète.\nQuelles sont vos attentes relativement aux valeurs des différents coefficients du modèle ? Quels sont ceux pour lesquels vous avez des doutes ?\n\nEstimez l’équation mentionnée en question (i) et reportez les résultats de façon standard. Quel est le différentiel de GPA estimé entre les athlètes et les non athlètes ? Cette différence est-elle statistiquement significative ?\nEnlevez sat du modèle et ré-estimez l’équation. Quel est maintenant l’effet estimé du statut d’athlète ? Discutez les raisons pour lesquelles ces résultats diffèrent de ceux présentées à la question (ii).\nDans le modèle décrit à la question (i), autorisez l’impact du statut d’athlète à différer selon le genre et testez l’hypothèse nulle d’absence de différence entre les femmes et les hommes athlètes, toutes choses égales par ailleurs.\nL’effet de sat sur colgpa diffère-t-il selon le genre ? Justifiez votre réponse.\n\n\n\n2.1.5 charity\nUtilisez les données contenues dans le fichier charity pour répondre à cette question. La variable respond est une variable indicatrice égale à un si un individu a répondu par un don à la sollicitation par mail la plus récente d’une association caritative. La variable resplast est une variable indicatrice égale à un si un individu a répondu à la sollicitation par mail précédente, avggift est la moyenne des dons passés (en florins néerlandais) et propresp est le temps relatif passé par la personne à répondre aux sollicitations passées.\n\nEstimez un modèle à probabilités linéaires expliquant respond en fonction de resplast et avggift. Reportez les résultats sous une forme usuelle et interprétez le coefficient de resplast.\nLa valeur moyenne des dons passés semble-t-elle affecter la probabilité de réponse ?\nAjoutez la variable propresp au modèle et interprétez son coefficient. (Soyez attentif ici : une hausse de une unité de propresp est le changement le plus important possible.)\nQu’est-il advenu du coefficient de resplast lorsque propresp a été ajouté au modèle de régression ? Cela a-t-il du sens ?\nAjoutez mailsyear, le nombre de mails envoyés par an, au modèle. Evaluez l’effet associé ? Pourquoi n’est-ce sans doute pas une mesure correcte de l’effet causal de l’envoi ciblé de mails (ou « publipostage ») sur la probabilité de réponse ?\n\n\n\n2.1.6 catholic\n\nConsidérez l’échantillon complet et identifiez quel pourcentage d’étudiants sont régulièrement inscrit dans un établissement secondaire d’obédience catholique. Quelle est la moyenne de la variable math12 ?\nRéalisez une régression simple de math12 sur cathhs et reportez les résultats selon les normes usuelles. Interprétez vos résultats.\nAjoutez maintenant les variables lfaminc, motheduc, et fatheduc au modèle de régression précédent. De combien d’observations disposez-vous pour cette régression ? Qu’advient-il du coefficient de la variable cathhs, apparaît-il significatif ?\nReprenez le cas d’une régression simple de math12 sur cathhs, en restreignant les observations à celles utilisées dans la régression multiple de la question (iii). Certaines de vos conclusions en sont-elles modifiées ?\nÀ partir du modèle de régression étudié en question (iii), ajoutez des variables d’interaction entre cathhs et chacune des autres variables explicatives du modèle. Ces variables d’interaction sont-elles individuellement et/ou conjointement significatives ?\nQu’advient-il du coefficient de cathhs dans la régression de la question (v). Expliquez pourquoi ce coefficient n’est pas très intéressant à étudier.\nCalculez l’effet marginal moyen de cathhs dans le model estimé en question (v). Comparez les résultats obtenus avec les coefficients de cathhs estimés dans la parties (iii) et (v).\n\n\n\n2.1.7 apple\n\nDéfinissez une variable binaire \\(ecobuy = 1\\) si \\(ecolbs &gt; 0\\) et \\(ecobuy = 0\\) si \\(ecolbs = 0\\). En d’autres termes, ecobuy indique si, à prix donnés, une famille consomme des pommes issues de l’agriculture biologique. Combien de familles affirment acheter des pommes labélisées bio ?\nEstimez le modèle à probabilités linéaires suivant : \\[ ecobuy = \\beta_0 + \\beta_1 ecoprc + \\beta_2 regprc + \\beta_3 faminc + \\beta_4 hhsize+ \\beta_5 educ+ \\beta_6 age \\] et reportez les résultats sous une forme usuelle. Interprétez avec soin les coefficients associés aux variables de prix.\nY-a-t-il des variables non associées aux prix qui soient conjointement significatives dans le modèle ? (Utilisez les statistiques de Fisher usuelles même si celles-ci ne sont pas valides en présence d’hétéroscédasticité.) Quelle variable explicative autre que les variables de prix semblent avoir l’effet le plus important sur la décision de consommer des pommes issues de l’agriculture biologique ? Cela vous paraît-il avoir du sens ?\nÀ partir du modèle discuté dans la question (ii), remplacez faminc par log(faminc). Lequel des deux modèles vous semble le mieux expliquer vos données celui introduisant faminc ou log(faminc) ? Interprétez le coefficient associé à log(faminc).\nSur base des estimations réalisées en question (iv), combien des probabilités estimées s’avèrent négatives ? Combien s’avèrent supérieures à l’unité ? En quoi cela devrait-il vous interpeler ?\nRevenons à l’estimation de la question (iv), calculez le pourcentage de prédictions correctes pour chacune des valeurs possible de la variable indépendante c’est-à-dire ecobuy = 0 puis ecobuy = 1. Quel résultat s’avère le mieux prédit par le modèle ?",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>TP 2 : Régression multiple et variables binaires</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP3.html",
    "href": "CMI-E2-TP3.html",
    "title": "3  Multicolinéarité",
    "section": "",
    "text": "#TP3 : Multicolinéarité\n\nknitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, eval=FALSE)\n\nlibrary(tidyverse)\nlibrary(wooldridge)\nlibrary(AER)\nlibrary(stargazer)\nlibrary(fixest)\nlibrary(AER)\nlibrary(calibrate)\nlibrary(PerformanceAnalytics)\nlibrary(ISLR)\nlibrary(corrplot)\nlibrary(mctest)\n\n%On considère le modèle général : %\\[ Y = X'\\beta + u\\]\nInstaller et charger les packages :\n\nISLR : contient le jeu de données `Auto}\ncorrplot : contient des fonctions de visualisation de matrice de correlation\nPerformanceAnalytics : contient des fonctions de visualisation de matrice de corrélation\nmctest : contient des fonctions de test de multicolinéarité\n\n\n3.0.1 Matrice de corrélation\n\nCharger les données Auto du package ISLR. Estimez le modèle :\n\n\\[mpg = \\beta_0 + \\beta_1 cylinders + \\beta_2  horsepower + \\beta_3  weight + \\beta_4 acceleration + \\beta_5 displacement + \\beta_6 year   + u \\]\n\nCalculer la matrice de corrélation des covariables avec la commande native cor.\nUtiliser la commande corrplot.mixed issue de corrplot. Pour visualiser cette matrice.\nMéthode alternative : utiliser la commande chart.Correlation(data, histogram=TRUE, pch=19) issue de PerformanceAnalytics.\nQue peut-on dire sur le niveau de multicolinéarité ? Commenter.\n\n\n\n3.0.2 VIF\n\nRappelez l’expression du Variance Inflation Factor \\(VIF_i\\) d’une covariable \\(i\\) en fonction de \\(R_i^2\\), le coefficient de détermination de la régression linéaire \\(X_i = \\gamma X_{-i}\\), avec \\(X_{-i}\\) étant tous les covariables autres que \\(X_i\\).\nEcrire une fonction VIF.test(X) qui associe à une matrice de covariables un vecteur contenant les \\(VIF_i\\) associés à chaque covariable \\(X_i\\). Indication : il faut faire \\(k\\) régressions et pour chaque régression, récupérer le \\(R^2\\) à l’aide de la commande summary(regression)$r.squared.\nVérifier votre fonction à l’aide de la fonction imcdiag de mctest.\n\n\n\n3.0.3 Test de Farrar et Glauber\nDans cette section, nous allons recoder le test de Farrar et Glauber. Il s’agit de créer une fonction qui prend un \\(model\\) issu d’une régression de \\(lm\\) et d’effectuer :\n\nExtraire la matrice des covariables en excluant le terme constant\nDéfinir la matrice de corrélation de cette matrice et calculer son déterminant \\(D\\).\nLa deuxième étape de ce test vise à effectuer un test du chi2 sur les hypothèses suivantes : $ {=tex}     \\begin{array}{cc}             H_0:  & D=1 \\\\             H_1:  & D&lt;1          \\end{array} $\n\nCalculer la statistique du Chi-2 associé au test de Farrar et Glauber : \\[ \\chi^2_{calc} =  - log(D)  \\big(n - 1 - \\frac{1}{6}(2k+7)\\big) \\] avec \\(n\\) est le nombre d’observations et \\(k\\) le nombre de covariables.\n\nCalculer la pvalue associée à \\(\\chi^2_{calc}\\). Le chi2 du test de Farrar et Glauber suit une loi du chi2 à \\(\\frac{1}{2}k(k+1)\\) degrés de liberté.\n\n\n\n3.0.4 Essais sur d’autres jeux de données\nAppliquez vos fonctions et sur les modèles et jeux de données des exercices 1, 2 et 3 du TP1.",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multicolinéarité</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP4.html",
    "href": "CMI-E2-TP4.html",
    "title": "4  Tests sur la forme fonctionnelle",
    "section": "",
    "text": "4.0.1 Test de Ramsey (RESET)\n#TP 4 : Forme fonctionnelle\nOn considère le modèle linéaire suivant :\n\\[ Y = X'\\beta + u\\]\nLe test de Ramsey cherche à tester si des spécifications non-linéaires n’apportent pas un pouvoir explicatif supérieur au modèle linéaire. Pour ce faire, on test si \\((X'\\beta)^2\\), \\((X'\\beta)^3\\), …, \\((X'\\beta)^m\\) on un effet significatif sur \\(Y\\).\n\\[ price = \\beta_0 + \\beta_1 lotsize + \\beta_2 sqrft + \\beta_3 bdrms \\] Puis le modèle augmenté :\n\\[ price = \\beta_0 + \\beta_1 lotsize + \\beta_2 sqrft + \\beta_3 bdrms + \\beta_4 \\widehat{price}^2 + \\beta_5 \\widehat{price}^3\\]\navec \\(\\widehat{price}\\) la prédiction de \\(price\\) du premier modèle.",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tests sur la forme fonctionnelle</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP4.html#exercices",
    "href": "CMI-E2-TP4.html#exercices",
    "title": "4  Tests sur la forme fonctionnelle",
    "section": "4.1 Exercices",
    "text": "4.1 Exercices\n\n4.1.1 kielmc\nUtilisez les données de kielmc, uniquement pour l’année 1981, pour répondre aux questions suivantes. Les données concernent les maisons vendues en 1981 à North Andover, Massachusetts ; 1981 est l’année du début de la construction d’un incinérateur d’ordures local.\n\nPour étudier les effets de l’emplacement de l’incinérateur sur le prix des logements, considérez le modèle de régression simple suivant :\n\n\\[log(prix) = \\beta_0 + \\beta_1 log(dist) + u\\]\noù le prix est le prix du logement en dollars et \\(dist\\) est la distance entre la maison et l’incinérateur, mesurée en pieds. En interprétant cette équation de manière causale, quel signe attendez-vous pour \\(\\beta_1\\) si la présence de l’incinérateur fait baisser les prix des logements ? Estimez cette équation et interprétez les résultats.\n\nAu modèle de régression simple de la partie 1. , ajoutez les variables log(\\(intst\\)), log(\\(area\\)), log(\\(land\\)), \\(rooms\\), \\(baths\\) et \\(age\\), où \\(intst\\) est la distance entre le domicile et l’inter-état, \\(area\\) est la superficie de la maison, land est la taille du terrain en pieds carrés, \\(rooms\\) est le nombre total de pièces, \\(baths\\) est le nombre de salles de bain et \\(age\\) est l’âge de la maison en années. Que concluez-vous sur les effets de l’incinérateur ? Expliquez pourquoi 1. et 2. donnent des résultats contradictoires.\nAjoutez\\(log(intst)^2\\) au modèle de la partie 2. . Que se passe-t-il maintenant ? Qu’en concluez-vous quant à l’importance de la forme fonctionnelle ?\nLe carré de log(\\(dist\\)) est-il significatif lorsque vous l’ajoutez au modèle de la partie 3. ?\n\n\n\n4.1.2 wage1\n\nUtilisez les MCO pour estimer l’équation suivante\n\n\\[log(wage) = \\beta_0 + \\beta_1e duc + \\beta_2 exper + \\beta_3 exper2 + u\\]\net présentez les résultats en utilisant le format habituel.\n\n\\(exper2\\) est-il statistiquement significatif au niveau de 1% ?\nEn utilisant l’approximation\n\ntrouvez le rendement approximatif de la cinquième année d’expérience. Quel est le rendement approximatif de la vingtième année d’expérience ? Quel est le rendement approximatif de la vingtième année d’expérience ?\n\nA partir de quelle valeur de \\(exper\\) l’expérience supplémentaire fait-elle baisser le log(\\(wage\\)) prédit ? Combien de personnes ont plus d’expérience dans cet échantillon ?\n\n\n\n4.1.3 gpa2\n\nEstimez le modèle\n\n\\[sat = \\beta_0 + \\beta_1 hsize + b2 hsize2 + u\\]\noù \\(hsize\\) est la taille de la classe de diplômés (en centaines), et écrivez les résultats sous la forme habituelle. Le terme quadratique est-il statistiquement significatif ?\n\nEn utilisant l’équation estimée dans la partie 1. , quelle est la taille “optimale” de l’école secondaire ? Justifiez votre réponse.\nCette analyse est-elle représentative des résultats scolaires de tous les élèves de terminale ? lycée ? Expliquez votre réponse.\nTrouvez la taille optimale estimée de l’école secondaire, en utilisant le log(\\(sat\\)) comme variable dépendante. variable dépendante. Est-ce très différent de ce que vous avez obtenu dans la partie 2. ?\n\n\n\n4.1.4 hprice1\n\nEstimez le modèle : \\[price = \\beta_0 + \\beta_1 lotsize + \\beta_2 sqrft + \\beta_3 bdrms + u \\]\n\n%\\[log(price) = \\beta_0 + \\beta_1 log(lotsize) + b2 log(sqrft) + \\beta_3 bdrms + u\\]\n\nTrouvez la valeur prédite de log(\\(price\\)), lorsque \\(lotsize\\) = 20,000, \\(sqrft\\) = 2,500, et \\(bdrms\\) = 4. En utilisant les méthodes de la section 6.4, trouvez la valeur prédite du prix pour les mêmes valeurs des variables explicatives. les mêmes valeurs des variables explicatives.\nPour expliquer la variation du prix, décidez si vous préférez le modèle de la partie 1. ou le modèle\n\n\n\n4.1.5 vote1\n\nConsidérons un modèle avec une interaction entre les dépenses :\n\n\\[voteA = \\beta_0 + \\beta_1 prtystrA + b2 expendA + \\beta_3 expendB + \\beta_4 expendA expendB + u\\]\nQuel est l’effet partiel de \\(expendB\\) sur \\(voteA\\), en maintenant fixes \\(prtystrA\\) et \\(expendA\\) ? Quel est l’effet partiel de \\(expendA\\) sur \\(voteA\\) ? Le signe attendu pour \\(\\beta_4\\) est-il évident ?\n\nEstimez l’équation de la partie 1. et présentez les résultats sous la forme habituelle. Le terme d’interaction est-il statistiquement significatif ?\nTrouver la moyenne de \\(expendA\\) dans l’échantillon. Fixer \\(expendA\\) à 300 (pour 300 000 $). Quel est l’effet estimé de 100 000 dollars supplémentaires dépensés par le candidat B sur le \\(voteA\\) ? S’agit-il d’un effet important ?\nFixez maintenant \\(expendB\\) à 100. Quel est l’effet estimé de \\(\\Delta expendA\\) = 100 sur le \\(voteA\\) ? Cela a-t-il un sens ?\nEstimez maintenant un modèle qui remplace l’interaction par \\(shareA\\), la part en pourcentage du candidat A dans les dépenses totales de la campagne. Est-il judicieux de maintenir les \\(expendA\\) et les \\(expendB\\) fixes, tout en modifiant la \\(shareA\\) ?\n(Nécessite des calculs) Dans le modèle de la partie 5. , trouvez l’effet partiel de \\(expendB\\) sur \\(voteA\\), en maintenant \\(prtystrA\\) et \\(expendA\\) fixes. Evaluez ceci à \\(expendA\\) = 300 et \\(expendB\\) = 0 et commentez les résultats.\n\n\n\n4.1.6 hprice1\n\nEstimez le modèle \\[prix = \\beta_0 + \\beta_1 lotsize + b2 sqrft + \\beta_3 bdrms + u\\]\n\net présentez les résultats sous la forme habituelle, y compris l’erreur standard de la régression. Obtenez le prix prédit, lorsque vous introduisez \\(lotsize\\) = 10,000, \\(sqrft\\) = 2,300, et \\(bdrms\\) = 4 ; arrondissez ce prix au dollar le plus proche.\n\nEffectuez une régression qui vous permette d’obtenir un intervalle de confiance de 95 % autour de la valeur prédite dans la partie 1. . Notez que votre prédiction sera légèrement différente en raison des erreurs d’arrondi.\nSoit \\(price_0\\) le prix de vente futur inconnu de la maison avec les caractéristiques utilisées dans les parties 1. et 2. . Trouvez un intervalle de confiance à 95% pour \\(price_0\\) et commentez la largeur de cet intervalle de confiance.\n\n\n\n4.1.7 nbsal\nL’ensemble de données nbsal contient des informations sur les salaires et des statistiques de carrière pour 269 joueurs de la National Basketball Association (NBA).\n\nEstimez un modèle reliant les points par match (\\(points\\)) aux années passées dans la ligue (\\(exper\\)), l’âge et le nombre d’années passées à l’université (\\(coll\\)). Inclure une quadratique dans \\(exper\\) ; les autres variables doivent apparaître sous forme de niveau. variables doivent apparaître sous forme de niveau. Rapportez les résultats de la manière habituelle.\nEn gardant les années d’université et l’âge fixes, à partir de quelle valeur d’expérience l’année d’expérience suivante réduit-elle réellement le nombre de points par match ? Cela a-t-il un sens ?\nPourquoi pensez-vous que \\(coll\\) a un coefficient négatif et statistiquement significatif ? (Indice : les joueurs de la NBA peuvent être recrutés avant la fin de leur carrière universitaire et même directement à la sortie du lycée).\nAjoutez une quadratique de l’âge à l’équation. Est-ce nécessaire ? Qu’est-ce que cela semble impliquer sur les effets de l’âge, une fois que l’expérience et l’éducation sont contrôlées ?\nRégressez maintenant log(\\(wage\\)) sur \\(points\\), \\(exper\\), \\(exper\\) , \\(age\\) et \\(coll\\).\nTestez si l’âge et le col sont conjointement significatifs dans la régression de la partie 5.\nQu’est-ce que cela implique quant à la question de savoir si l’âge et l’éducation ont des effets distincts sur le salaire, une fois que la productivité et l’ancienneté sont prises en compte ?\n\n\n\n4.1.8 bwght2\n\nEstimez le modèle :\n\n\\[log(bwght) = \\beta_0 + \\beta_1 npvis + b2 npvis2 + u \\]\npar la méthode des moindres carrés ordinaires (MCO), et rapportez les résultats de la manière habituelle. Le terme quadratique est-il significatif ?\n\nMontrez que, sur la base de l’équation de la partie 1. , le nombre de visites prénatales qui maximise le log(\\(bwght\\)) est estimé à environ 22. Combien de femmes ont eu au moins 22 visites prénatales dans l’échantillon ?\nEst-il logique de prédire que le poids de naissance diminue après 22 visites prénatales ? Expliquez pourquoi.\nAjoutez l’âge de la mère à l’équation, en utilisant une forme fonctionnelle quadratique. En maintenant \\(npvis\\) fixe, à quel âge de la mère le poids de naissance de l’enfant est-il maximisé ? Quelle fraction des femmes de l’échantillon est plus âgée que la moyenne ? Quelle fraction des femmes de l’échantillon est plus âgée que l’âge “optimal” ?\nDiriez-vous que l’âge de la mère et le nombre de visites prénatales expliquent une grande partie de la variation du log(\\(bwght\\)) ?\nEn utilisant des quadratiques pour le \\(npvis\\) et l’âge, décidez si l’utilisation du logarithme naturel ou du niveau de \\(bwght\\) est meilleure que l’utilisation du logarithme de l’âge.\n\n\n\n4.1.9 apple\n\nExécutez la régression \\(ecolbs\\) sur \\(ecoprc\\) et \\(regprc\\) et reportez les résultats. Présentez les résultats sous la forme d’un tableau, y compris le R-carré et le R-carré ajusté. Interprétez les coefficients sur les variables de prix et commentez leurs signes. les variables de prix et commentez leurs signes et leurs amplitudes.\nLes variables de prix sont-elles statistiquement significatives ? Indiquez les valeurs p pour les tests t individuels. pour les différents tests t.\nQuel est l’éventail des valeurs ajustées pour \\(ecolbs\\) ? Quelle fraction de l’échantillon rapporte \\(ecolbs\\) = 0 ? Commenter.\nPensez-vous que l’ensemble des variables de prix explique bien la variation de l’indice \\(ecolbs\\) ? Expliquez.\nAjoutez les variables \\(faminc\\), \\(hhsize\\) (taille du ménage), \\(educ\\), et \\(age\\) à la régression de la partie 1. . Trouvez la valeur p pour leur signification conjointe. Qu’en concluez-vous ?\nEffectuez des régressions simples séparées de \\(ecolbs\\) sur \\(ecoprc\\), puis de \\(ecolbs\\) sur \\(regprc\\). Comment les coefficients de régression simple se comparent-ils à la régression multiple de la partie 1. ? Trouvez le coefficient de corrélation entre \\(ecoprc\\) et \\(regprc\\) pour expliquer vos résultats.",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tests sur la forme fonctionnelle</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP5.html",
    "href": "CMI-E2-TP5.html",
    "title": "5  Tests sur l’hétéroscédasticité",
    "section": "",
    "text": "6 Erreurs standards robustes\n#TP 5 : Heteroscedasticité\n%Le but de cette partie est de recoder les fonctions bptest du package lmtest et les données de CASchools\nOn considère le modèle linéaire suivant :\n\\[ Y = X'\\beta + u\\]\nLe but de cette section est de recoder une fonction effectuant des tests de Breush-Pagan et de White.",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tests sur l'hétéroscédasticité</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP5.html#sleep75",
    "href": "CMI-E2-TP5.html#sleep75",
    "title": "5  Tests sur l’hétéroscédasticité",
    "section": "8.1 sleep75",
    "text": "8.1 sleep75\nConsidérez le modèle suivant pour expliquer le comportement de sommeil : \\[sleep = \\beta_0+ \\beta_1 totwrk + \\beta_2 educ + \\beta_3 age + \\beta_4 age^2 + \\beta_5 yngkid + \\beta_6 male + u \\]\n\nRédigez un modèle qui permet à la variance de \\(u\\) de différer entre les hommes et les femmes. La variance ne doit pas dépendre d’autres facteurs.\nUtilisez les données de sleep75 pour estimer les paramètres du modèle pour l’hétéroscédasticité. (Vous devez d’abord estimer l’équation du sommeil par les MCO pour obtenir les résidus des MCO). La variance estimée de \\(u\\) est-elle plus élevée pour les hommes ou pour les femmes ?\nLa variance de \\(u\\) est-elle statistiquement différente pour les hommes et pour les femmes ?",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tests sur l'hétéroscédasticité</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP5.html#vote1",
    "href": "CMI-E2-TP5.html#vote1",
    "title": "5  Tests sur l’hétéroscédasticité",
    "section": "8.2 vote1",
    "text": "8.2 vote1\n\nEstimez un modèle avec voteA comme variable dépendante et \\(prtystrA\\), \\(democA\\), \\(log(expendA)\\), et \\(log(expendB)\\) comme variables indépendantes. Obtenez les résidus des MCO, \\(\\hat{u}_i\\), et régressez-les sur toutes les variables indépendantes. Expliquez pourquoi vous obtenez \\(R^2 = 0\\).\nCalculez maintenant le test de Breusch-Pagan pour l’hétéroscédasticité. Relevez la valeur de la statistique F et indiquez la valeur p.\nCalculez le cas particulier du test de White pour l’hétéroscédasticité, en relevant à nouveau la valeur de la statistique F. Quelle est la force de la preuve de l’hétéroscédasticité maintenant ?",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tests sur l'hétéroscédasticité</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP5.html#pntsprd",
    "href": "CMI-E2-TP5.html#pntsprd",
    "title": "5  Tests sur l’hétéroscédasticité",
    "section": "8.3 pntsprd",
    "text": "8.3 pntsprd\n\nLa variable \\(sprdcvr\\) est une variable binaire égale à un si l’écart de points de Las Vegas pour un match de basket universitaire a été couvert. La valeur attendue de \\(sprdcvr\\), soit \\(\\mu\\), est la probabilité que l’écart soit couvert lors d’un match choisi au hasard. Testez H0 : \\(\\mu = 0.5\\) contre H1 : \\(\\mu \\neq .5\\) au niveau de signification de 10 % et discutez vos résultats. (Conseil : ceci est facilement réalisable à l’aide d’un test de student en régressant \\(sprdcvr\\) sur une ordonnée à l’origine uniquement).\nCombien de matchs dans l’échantillon de 553 ont été joués sur un terrain neutre ?\nEstimer le modèle de probabilité linéaire\n\n\\[sprdcvr = \\beta_0 + \\beta_1 favhome + \\beta_2 neutral + \\beta_3 fav25 +\\beta_4 und25 + u\\]\net présenter les résultats sous la forme habituelle. (Indiquez les erreurs standard habituelles des MCO et les erreurs standard corrigées de l’hétéroscédasticité). Quelle variable est la plus significative, à la fois d’un point de vue pratique et statistique ?\n\nExpliquez pourquoi, sous l’hypothèse nulle H0 : \\(\\beta_1= \\beta_2= \\beta_3= \\beta_4= 0\\), il n’y a pas d’hétéroscédasticité dans le modèle.\nUtilisez la statistique F habituelle pour tester l’hypothèse de la partie iv). Quelle est votre conclusion ?\nCompte tenu de l’analyse précédente, diriez-vous qu’il est possible de prédire systématiquement si l’écart de Las Vegas sera couvert en utilisant les informations disponibles avant le match ?",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tests sur l'hétéroscédasticité</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP5.html#loanapp",
    "href": "CMI-E2-TP5.html#loanapp",
    "title": "5  Tests sur l’hétéroscédasticité",
    "section": "8.4 loanapp",
    "text": "8.4 loanapp\n\nEstimez l’équation avec \\(approve\\) comme variable d’intérêt et comme variables explicatives : \\(white\\) , \\(hrat\\), \\(obrat\\), \\(loanprc\\), \\(unem\\), \\(male\\), \\(married\\), \\(dep\\), \\(sch\\), \\(cosign\\), \\(chist\\), \\(pubrec\\), \\(mortlat1\\), \\(mortlat2\\), et \\(vr\\).\n\nCalculer les erreurs standard hétéroscédastiques robustes. Comparez l’intervalle de confiance à 95% sur \\(\\beta_{white}\\) avec l’intervalle de confiance non robuste.\n\nObtenez les valeurs ajustées de la régression de la partie 1. Certaines d’entre elles sont-elles inférieures à zéro ? Certaines d’entre elles sont-elles supérieures à un ? Qu’est-ce que cela signifie pour l’application des moindres carrés pondérés ?",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tests sur l'hétéroscédasticité</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP5.html#gpa1",
    "href": "CMI-E2-TP5.html#gpa1",
    "title": "5  Tests sur l’hétéroscédasticité",
    "section": "8.5 gpa1",
    "text": "8.5 gpa1\n\nUtilisez les MCO pour estimer un modèle reliant \\(colgpa\\) à \\(hsGPA\\), \\(ACT\\), \\(skipped\\) et \\(PC\\). Résidus des MCO.\nCalculez le cas particulier du test de White pour l’hétéroscédasticité. Dans la régression de \\(\\hat{u}_i^2\\) sur \\(\\hat{colgpa}_i\\) , \\(\\hat{colgpa}_i^2\\) obtenez les valeurs ajustées \\(\\hat{h}_i\\).\nVérifiez que les valeurs ajustées de la partie 2. sont toutes strictement positives. Ensuite, obtenez les estimations des moindres carrés pondérés en utilisant les poids \\(1/ \\hat h_i\\). Comparez les estimations des moindres carrés pondérés pour l’effet de l’absence de cours et l’effet de la possession d’un ordinateur avec les estimations des MCO correspondantes. Quelle est leur signification statistique ?\nDans l’estimation WLS de la partie 3, obtenez des erreurs standard corrigées de l’hétéroscédasticité. En d’autres termes, tenir compte du fait que la fonction de variance estimée dans la partie 2. puisse être mal spécifiée. Les erreurs standard changent-elles beaucoup par rapport à la partie 3. ?",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tests sur l'hétéroscédasticité</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP5.html#meap00",
    "href": "CMI-E2-TP5.html#meap00",
    "title": "5  Tests sur l’hétéroscédasticité",
    "section": "8.6 meap00",
    "text": "8.6 meap00\n\nEstimez le modèle :\n\n\\[math4 = \\beta_0 + \\beta_1lunch + \\beta_2 \\log(enroll) + \\beta_3 \\log(exppp) + u\\] par MCO et obtenez les erreurs standard habituelles et les erreurs standard entièrement robustes. Comment se comparent-elles en général ?\n\nAppliquez le cas particulier du test de White pour l’hétéroscédasticité. Quelle est la valeur du test F ? Qu’en concluez-vous ?\nObtenez \\(\\hat g_i\\) comme valeurs ajustées de la régression \\(log(\\hat{u}^2_i )\\) sur \\(\\hat{math4}_i\\), \\(\\widehat math4^2_i\\) où \\(\\widehat math4_i\\) sont les valeurs ajustées OLS et \\(\\hat{u}_i\\) sont les résidus OLS. Soit \\(h_i = exp(g_i)\\). Utilisez les \\(\\hat h_i\\) pour obtenir les estimations des MCO. Y a-t-il de grandes différences avec les coefficients des MCO ?\nObtenez les erreurs standard pour les MCO qui permettent une mauvaise spécification de la fonction de variance. Sont-elles très différentes des erreurs standard habituelles des MCO ?\nPour estimer l’effet des dépenses en \\(math4\\), les MCO ou les MCO semblent-ils plus précis ?",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tests sur l'hétéroscédasticité</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP5.html#fertil2",
    "href": "CMI-E2-TP5.html#fertil2",
    "title": "5  Tests sur l’hétéroscédasticité",
    "section": "8.7 fertil2",
    "text": "8.7 fertil2\nUtilisez les données de fertil2 pour répondre à cette question.\n\nEstimez le modèle \\[enfants = \\beta_0+ \\beta_1 age + \\beta_2 age^2 + \\beta_3 educ + \\beta_4 electric + \\beta_5 urban + u\\]\n\net présentez les erreurs standard habituelles et corrigées de l’hétéroscédasticité. Les erreurs standard robustes sont-elles toujours plus grandes que les erreurs standard non robustes ? Les erreurs standard robustes sont-elles toujours plus grandes que les erreurs standard non robustes ?\n\nAjoutez les trois variables muettes religieuses et testez si elles sont conjointement significatives. significatives. Quelles sont les valeurs p pour les tests non robustes et robustes ?\nA partir de la régression de la partie 2. , obtenez les valeurs ajustées \\(\\hat y\\) et les résidus, \\(\\hat u\\). Régressez \\(\\hat{u}^2\\) sur \\(\\hat{y}\\) et \\(\\hat{y}^2\\) et testez la signification conjointe des deux régresseurs. Concluez que l’hétéroscédasticité est présente dans l’équation pour les enfants.\nDiriez-vous que l’hétéroscédasticité que vous avez trouvée dans la partie 3. est pratiquement importante dans la pratique ?",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tests sur l'hétéroscédasticité</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP5.html#beauty",
    "href": "CMI-E2-TP5.html#beauty",
    "title": "5  Tests sur l’hétéroscédasticité",
    "section": "8.8 beauty",
    "text": "8.8 beauty\nUtilisez les données de beauty pour cette question. 1. En utilisant les données regroupées pour les hommes et les femmes, estimez l’équation\n\\[  lwage = \\beta_0 + \\beta_1 belavg + \\beta_2 abvavg + \\beta_3 female + \\beta_4 educ + \\beta_5 exper + \\beta_6 exper^2 + u \\]\net présentez les résultats en utilisant des erreurs standard corrigées de l’hétéroscédasticité sous les coefficients. Certains des coefficients sont-ils surprenants, que ce soit par leur signe ou par leur ampleur ? Le coefficient de la femme est-il pratiquement grand et statistiquement significatif ?\n\nAjoutez les interactions de la variable “femme” avec toutes les autres variables explicatives dans l’équation de la partie 1. (cinq interactions en tout). Calculer le test F habituel de signification conjointe des cinq interactions et une version corrigée de l’hétéroscédasticité. L’utilisation de la version corrigée de l’hétéroscédasticité modifie-t-elle le résultat de manière importante ?\nDans le modèle complet avec interactions, déterminer si celles impliquant les variables de look - femme - \\(belavg\\) et femme - \\(abvavg\\) - sont conjointement significatives. Leurs coefficients sont-ils pratiquement faibles ?",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tests sur l'hétéroscédasticité</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP6.html",
    "href": "CMI-E2-TP6.html",
    "title": "6  Estimateurs pour les données de panel",
    "section": "",
    "text": "6.1 Exercices\n#TP 6 : Econométrie de Panel",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Estimateurs pour les données de panel</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP6.html#exercices",
    "href": "CMI-E2-TP6.html#exercices",
    "title": "6  Estimateurs pour les données de panel",
    "section": "",
    "text": "6.1.1 fertil1\n\nEstimez le modèle OLS avec kids comme variable dépendente : lm(data=fertil1, kids ~ educ + age + agesq + black + east + northcen + west + farm + othrural + town + y74 + y76 + y78 + y80 + y82 + y84)\nDans l’équation estimée précédemment, testez si le cadre de vie à l’âge de 16 ans a un effet sur la fertilité (town). (Le groupe de référence est la grande ville). Reportez la valeur de la statistique F et sa p-valeur.\nTestez si la région (east,northcen, west) du pays dans laquelle on vit à l’âge de 16 ans (le groupe de référence est celui du Sud) a un effet sur la fertilité.\nSoit u le terme d’erreur de l’équation de la population. Supposez que la variance de u change au cours du temps (mais pas avec educ, age, etc.). Un modèle tenant compte de cela peut s’écrire ainsi : \\[u^2 =\\gamma_0 +\\gamma_1 y74+\\gamma_2 y76+...+\\gamma_6 y84+ v\\] En utilisant ce modèle, testez l’hétéroscédasticité de u. (Indice : votre test F doit avoir 6 000 et 1 122 degrés de liberté).\nAjoutez les termes d’interactione entre educ et les variables binaires sur les années au modèle estimé dans la question i. Expliquez ce que représentent ces termes. Sont-ils conjointement significatifs ?\n\n\n\n6.1.2 cps78_85\n\nEstimez le modèle suivant : \\[lwage = y85 + educ + y85 \\times educ + exper + exper^2 + union + female + y85 \\times female \\]\nComment interprétez-vous le coefficient de y85 dans le modèle ? A-t-il une interprétation intéressante ? (Soyez prudent ici ; vous devez expliquer les termes d’interactions y85·educ et y85·female.) iIi. En maintenant fixés les autres facteurs, quel est le pourcentage estimé d’augmentation du salaire nominal d’un homme ayant fait 12 ans d’études ? Proposez une régression permettant d’obtenir un intervalle de confiance pour cette estimation. [Indice : pour obtenir l’intervalle de confiance, remplacez y85·educ par y85(educ – 12)\nFaites une nouvelle estimation du modèle en exprimant tous les salaires en dollars de 1978. En particulier, définissez le salaire réel comme rwage = wage pour 1978 et comme rwage = wage/1,65 pour 1985. Utilisez maintenant log(rwage) à la place de log(wage). Quels sont les coefficients qui changent au modèle i. ?\n\n\n\n6.1.3 kielmc\nPour cet exercice, utilisez les données du fichier kielmc i. La variable dist est la distance entre chaque maison et le site de l’incinérateur, en pieds. Examinez le modèle suivant : \\[log(price) = \\beta_0 + \\delta_0 y81 + \\beta_1 log(dist) + \\delta_1 y81· log(dist) + u.\\]\nSi la construction de l’incinérateur réduit la valeur des maisons proches du site, quel est le signe attendu de \\(\\delta_1\\) ? Qu’est-ce que cela signifie si \\(\\beta_1\\) &gt; 0 ?\n\nEstimez le modèle de la question (i) et reportez les résultats sous la forme habituelle. Interprétez le coefficient de y81· log(dist). Que pouvez-vous en conclure ?\nAjoutez age, age2, rooms, baths, log(intst), log(land), etlog(area) à l’équation. Maintenant, que pouvez-vous conclure concernant l’effet de la présence de l’incinérateur sur la valeur des logements ?\nPourquoi le coefficient de log(dist) est-il positif et statistiquement significatif à la question (ii) mais pas à la question (iii) ? Qu’est-ce que cela nous apprend sur les variables de contrôle introduites à la question (iii) ?\n\n\n\n6.1.4 injury\n\nEn utilisant les données du Kentucky, estimez le modèle \\[log(durat) =  afchnge + highearn + afchnge*highearn + male + married\\]\n\net y ajouter les variables explicatives jeu entier de variables indicatrices pour les industries et les types d’accidents du travail (les transformer en facteurs au préalables). Comment l’estimation de afchnge.highearn varie lorsque ces autres facteurs sont pris en compte ? Est-ce que cette estimation est statistiquement significative ? ii. Comment interprétez-vous les faibles valeurs de R carré de la question (i) ? Cela signifie-t-il que l’équation est inutile ? iii. Estimez le modèle de i. en utilisant les données pour le Michigan. Comparez les estimations sur le terme d’interaction pour le Michigan et le Kentucky. Est-ce que l’estimation pour le Michigan est statistiquement significative ? Justifiez.\n\n\n6.1.5 rental\nLes données pour les années 1980 et 1990 incluent le prix des loyers ainsi que d’autres variables caractérisant les villes dans lesquelles sont établies des universités. L’idée est de voir si la présence d’un nombre élevé d’étudiants fait augmenter les loyers. Le modèle à effets non observés est : \\[log(rentit) =   y90t + \\log(popit) + log(avgincit) +  pctstuit + a_i + u_{it}\\], où pop est la population de la ville, avginc est le revenu moyen, et pctstu est le nombre d’étudiants exprimé en pourcentage de la population de la ville (au cours de l’année scolaire). i. Estimez l’équation par la méthode des MCO sur données empilées et reportez les résultats. Que pouvez-vous conclure ?\n\nLes écarts-types estimés que vous avez reportés dans la question (i) sont-ils valides ? Justifiez.\nMaintenant, exprimez l’équation en différences et estimez-la par les MCO. Comparez votre estimation de \\(\\beta_3\\) avec celle de la question (ii). Est-ce que la taille relative de la population d’étudiants semble affecter les prix des loyers ?\nObtenez les écarts-types estimés robustes à l’hétéroscédasticité pour l’équation en différences premières de la question (iii). Cela modifie-t-il vos conclusions ?\n\n\n\n6.1.6 jtrain\nPour cet exercice, nous utilisons les données contenues dans la base JTRAIN pour étudier l’effet des subventions à la formation professionnelle sur la formation professionnelle par employé. Le modèle de base pour les trois années est donné par :\n\\[hrsempit = \\beta_0 + \\delta_1 d88_t + \\delta_2 d89_t     + \\beta_1 grant_{it} + \\beta_2 grant_{i,t–1} + \\beta_3 log(employ_{it}) + a_i + u_{it}\\]\n\nEstimez l’équation en utilisant des effets fixes. Combien de firmes sont utilisées dans cette estimation ? Combien d’observations seraient utilisées si chacune des entreprises disposait de données pour l’ensemble des variables explicatives du modèle (et en particulier, hrsemp) pour chacune des trois années ?\nInterprétez le coefficient relatif à grant et commentez sa significativité.\nCela vous surprend-il que le coefficient associé à grant–1 ne soit pas significatif ? Justifiez.\nLes grandes entreprises proposent-elles à leurs employés plus ou moins de temps de formation en moyenne ? De quel ordre sont les différences ? (Par exemple, si une entreprise a 10 % d’employés en plus, quel est le changement relatif dans le nombre d’heures allouées à la formation professionnelle ?)",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Estimateurs pour les données de panel</span>"
    ]
  },
  {
    "objectID": "CMI-E2-TP6.html#murder",
    "href": "CMI-E2-TP6.html#murder",
    "title": "6  Estimateurs pour les données de panel",
    "section": "6.2 murder",
    "text": "6.2 murder\nNous utilisons les données étatiques relatives aux taux de criminalité et d’exécution issues du fichier MURDER pour l’exercice qui suit.\n\nConsidérons le modèle à effets inobservés suivant : \\[mrdrte_{it} = \\eta_t + \\beta_1 exec_{it} + \\beta_2 unem_{it} + a_i + u_{it}\\] avec \\(\\eta_t\\) les différentes variables indicatrices temporelles et ai l’effet inobservé relatif à l’appartenance à un État donné. Si les exécutions passées de personnes jugées coupables de meurtres avaient eu un effet dissuasif, quel aurait dû être le signe de \\(\\beta_1\\) ? À votre avis, quel devrait être le signe de \\(\\beta_2\\) ? Justifiez.\nEn restreignant l’étude aux années 1990 et 1993, estimez l’équation considérée à la question (i) au moyen d’une estimation par les MCO sur les données empilées. Ignorez le problème de corrélation sérielle dans le terme d’erreur composé. Les résultats d’estimation sont-ils en faveur de l’hypothèse d’un effet dissuasif de la peine capitale ?\nEn vous focalisant toujours sur les années 1990 et 1993, estimez maintenant le modèle au moyen d’effets fixes. Vous pouvez recourir aux différences premières puisque vous n’utilisez que deux années de données. Vos résultats sont-ils maintenant en faveur de l’hypothèse d’un effet dissuasif de la peine capitale ? Ce résultat est-il robuste ?\nCalculez les écarts-types estimés robustes à l’hétéroscédasticité des paramètres estimés du modèle décrit en question (ii).\nIdentifiez l’État qui présente le nombre le plus important d’exécutions en 1993. (La variable exec correspond au nombre total d’exécutions réalisées en 1991, 1992, et 1993.) Identifiez le deuxième État en matière d’exécutions en 1993. Combien d’exécutions les séparent ?\nEstimez l’équation par la méthode des différences premières, en retirant l’État du Texas de votre ana- lyse. Calculez les écarts-types standard et ceux robustes à l’hétéroscédasticité. Que trouvez-vous ? Que se passe-t-il ?\nUtilisez maintenant les trois années de données dont vous disposez et estimez le modèle à effets fixes. Introduisez l’État du Texas dans votre analyse. Discutez la taille et la significativité de l’effet dissuasif de la peine capitale comparativement aux effets mis en exergue dans les questions précédentes lorsque les seules années 1990 et 1993 étaient considérées.",
    "crumbs": [
      "Econométrie 2",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Estimateurs pour les données de panel</span>"
    ]
  }
]